{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc141f68",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ecdc963a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ada_csl_wrc.evaluation import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d03c0ff0",
      "metadata": {
        "id": "d03c0ff0",
        "outputId": "d7340cbf-3b21-4536-f20c-0320f6f3e2c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from ada_csl_wrc.models import CostSensitiveDecisionTreeClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from ada_csl_wrc.models import ConstrainedCSDecisionTree\n",
        "from ada_csl_wrc.models import Constrained\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ada_csl_wrc.utils import prediction_up_to_constraint\n",
        "import pandas as pd\n",
        "from ada_csl_wrc.utils import prepare_for_cost_cle\n",
        "from ada_csl_wrc.utils import filter_only_worst_features\n",
        "from ada_csl_wrc.utils import find_effective_threshold\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f88a034",
      "metadata": {},
      "source": [
        "### Hyperparameters of the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2af89146",
      "metadata": {},
      "outputs": [],
      "source": [
        "COST_FALSE_NEGATIVE = 10\n",
        "COST_FALSE_POSITIVE = 1\n",
        "t = COST_FALSE_POSITIVE/(COST_FALSE_POSITIVE+COST_FALSE_NEGATIVE)\n",
        "COST_MATRIX = np.array([[0, COST_FALSE_POSITIVE], [COST_FALSE_NEGATIVE, 0]])\n",
        "FEATURES_RATIO = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436a7492",
      "metadata": {},
      "source": [
        "### Data-specific code\n",
        "\n",
        "This part includes some data-specific code. It is not included in the final model. <br>\n",
        "The X and the y are the dataframes that are used for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "829244f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('./data/marketing_campaign.csv', sep=\";\")\n",
        "df = df.drop(['Z_CostContact', 'Z_Revenue', 'Income', 'Dt_Customer', 'ID'], axis = 1)\n",
        "X = df.drop(labels = 'Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "#Transforming categorial features into numerical\n",
        "categorial_col = X.select_dtypes(include='object').columns\n",
        "X[categorial_col] = X[categorial_col].astype('category').apply(lambda x: x.cat.codes)\n",
        "X = filter_only_worst_features(X, y, FEATURES_RATIO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a6865d5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_params(param_grid, X, y):\n",
        "    # Used for this dataset specifically, to find the best parameters for the decision tree\n",
        "    # Let's think about more general way to do so.\n",
        "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10, n_jobs=-1, scoring='f1', verbose=3)\n",
        "    grid.fit(X, y)\n",
        "    return grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "d190ffb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_param_grid = {\n",
        "    \"max_depth\": [3, 5, 10, 15],\n",
        "    \"criterion\": [\"gini\", \"entropy\"],\n",
        "    \"min_samples_leaf\": [10, 15, 20, 30]\n",
        "}\n",
        "\n",
        "cs_best_params = json.load(open(\"./config/cost_sensitive_best_params.json\", \"r\")) #hard-coded in a json file\n",
        "#dt_best_params = find_best_params(dt_param_grid, X, y) #find it using grid search\n",
        "dt_best_params = {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 20}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc488125",
      "metadata": {},
      "source": [
        "If you have reached here, it means that you have in memory the dt_best_params and cs_best_params. <br>\n",
        "We will inititate our base-classifier based on these params. However, the results of the experiment might be affected by this choice. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28376b4",
      "metadata": {},
      "source": [
        "## Starting the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "e3c260ba",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constraints_range = 0.25, 0.75\n",
        "test_size = round(len(X)/3)\n",
        "int(constraints_range[0]*test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05c0825",
      "metadata": {},
      "source": [
        "### Decision Tree\n",
        "With best params from the grid search, applying on various of constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5966fd99",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_constrained_experiment(constrained_model:Constrained, \n",
        "                               X, \n",
        "                               y, \n",
        "                               cost_matrix, \n",
        "                               constraint:list, \n",
        "                               random_state=42, \n",
        "                               n_splits=3):\n",
        "\n",
        "    fit_params = {}\n",
        "    out = {}\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    \n",
        "    for (fold, (train_index, test_index)) in enumerate(kf.split(X, y)):\n",
        "        #The ordinary Kfold, but with the constraint\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        if isinstance(constrained_model.model, CostSensitiveDecisionTreeClassifier):\n",
        "            #The Cost Sensitive Decision Tree also needs the cost matrix as a fit parameter\n",
        "            fit_params['cost_mat'] = prepare_for_cost_cle(len(X_train), cost_matrix)\n",
        "\n",
        "        constrained_model.fit(X_train, y_train, **fit_params) #Fitting the model\n",
        "\n",
        "        #The constraint is a float between 0 and 1\n",
        "        y_pred = constrained_model.predict_constrained(X_test, constraint=constraint)\n",
        "        out[fold] = evaluate(y_test, y_pred, cost_matrix)\n",
        "\n",
        "    return pd.DataFrame(out).T.mean(axis=0).to_dict() #Returning the mean of the metrics\n",
        "\n",
        "results = {}\n",
        "for constraint in np.arange(0.00, 0.99, 0.005).round(3):\n",
        "    print(constraint)\n",
        "\n",
        "    partial_results = run_constrained_experiment(Constrained(DecisionTreeClassifier(**dt_best_params)),\n",
        "                                X.values,\n",
        "                                y.values,\n",
        "                                COST_MATRIX,\n",
        "                                constraint=constraint)\n",
        "    results[constraint] = partial_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "8bc3889f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cost': 872,\n",
              " 'accuracy': 0.8324396782841823,\n",
              " 'precision': 0.3,\n",
              " 'recall': 0.1782178217821782,\n",
              " 'f1': 0.2236024844720497}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.333)\n",
        "\n",
        "absolute_constraint = 60\n",
        "constraint = absolute_constraint/len(y_test)\n",
        "dt = Constrained(DecisionTreeClassifier(**dt_best_params))\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_constrained = dt.predict_constrained(X_test, constraint=constraint)\n",
        "evaluate(y_test, y_pred_constrained, COST_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb7e57f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d49a6b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ce60ec",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c058d9fb",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "de74f1ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.005\n",
            "0.01\n",
            "0.015\n",
            "0.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\imargolin\\Anaconda3\\envs\\ucp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\imargolin\\Anaconda3\\envs\\ucp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\imargolin\\Anaconda3\\envs\\ucp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.025\n",
            "0.03\n",
            "0.035\n",
            "0.04\n",
            "0.045\n",
            "0.05\n",
            "0.055\n",
            "0.06\n",
            "0.065\n",
            "0.07\n",
            "0.075\n",
            "0.08\n",
            "0.085\n",
            "0.09\n",
            "0.095\n",
            "0.1\n",
            "0.105\n",
            "0.11\n",
            "0.115\n",
            "0.12\n",
            "0.125\n",
            "0.13\n",
            "0.135\n",
            "0.14\n",
            "0.145\n",
            "0.15\n",
            "0.155\n",
            "0.16\n",
            "0.165\n",
            "0.17\n",
            "0.175\n",
            "0.18\n",
            "0.185\n",
            "0.19\n",
            "0.195\n",
            "0.2\n",
            "0.205\n",
            "0.21\n",
            "0.215\n",
            "0.22\n",
            "0.225\n",
            "0.23\n",
            "0.235\n",
            "0.24\n",
            "0.245\n",
            "0.25\n",
            "0.255\n",
            "0.26\n",
            "0.265\n",
            "0.27\n",
            "0.275\n",
            "0.28\n",
            "0.285\n",
            "0.29\n",
            "0.295\n",
            "0.3\n",
            "0.305\n",
            "0.31\n",
            "0.315\n",
            "0.32\n",
            "0.325\n",
            "0.33\n",
            "0.335\n",
            "0.34\n",
            "0.345\n",
            "0.35\n",
            "0.355\n",
            "0.36\n",
            "0.365\n",
            "0.37\n",
            "0.375\n",
            "0.38\n",
            "0.385\n",
            "0.39\n",
            "0.395\n",
            "0.4\n",
            "0.405\n",
            "0.41\n",
            "0.415\n",
            "0.42\n",
            "0.425\n",
            "0.43\n",
            "0.435\n",
            "0.44\n",
            "0.445\n",
            "0.45\n",
            "0.455\n",
            "0.46\n",
            "0.465\n",
            "0.47\n",
            "0.475\n",
            "0.48\n",
            "0.485\n",
            "0.49\n",
            "0.495\n",
            "0.5\n",
            "0.505\n",
            "0.51\n",
            "0.515\n",
            "0.52\n",
            "0.525\n",
            "0.53\n",
            "0.535\n",
            "0.54\n",
            "0.545\n",
            "0.55\n",
            "0.555\n",
            "0.56\n",
            "0.565\n",
            "0.57\n",
            "0.575\n",
            "0.58\n",
            "0.585\n",
            "0.59\n",
            "0.595\n",
            "0.6\n",
            "0.605\n",
            "0.61\n",
            "0.615\n",
            "0.62\n",
            "0.625\n",
            "0.63\n",
            "0.635\n",
            "0.64\n",
            "0.645\n",
            "0.65\n",
            "0.655\n",
            "0.66\n",
            "0.665\n",
            "0.67\n",
            "0.675\n",
            "0.68\n",
            "0.685\n",
            "0.69\n",
            "0.695\n",
            "0.7\n",
            "0.705\n",
            "0.71\n",
            "0.715\n",
            "0.72\n",
            "0.725\n",
            "0.73\n",
            "0.735\n",
            "0.74\n",
            "0.745\n",
            "0.75\n",
            "0.755\n",
            "0.76\n",
            "0.765\n",
            "0.77\n",
            "0.775\n",
            "0.78\n",
            "0.785\n",
            "0.79\n",
            "0.795\n",
            "0.8\n",
            "0.805\n",
            "0.81\n",
            "0.815\n",
            "0.82\n",
            "0.825\n",
            "0.83\n",
            "0.835\n",
            "0.84\n",
            "0.845\n",
            "0.85\n",
            "0.855\n",
            "0.86\n",
            "0.865\n",
            "0.87\n",
            "0.875\n",
            "0.88\n",
            "0.885\n",
            "0.89\n",
            "0.895\n",
            "0.9\n",
            "0.905\n",
            "0.91\n",
            "0.915\n",
            "0.92\n",
            "0.925\n",
            "0.93\n",
            "0.935\n",
            "0.94\n",
            "0.945\n",
            "0.95\n",
            "0.955\n",
            "0.96\n",
            "0.965\n",
            "0.97\n",
            "0.975\n",
            "0.98\n",
            "0.985\n"
          ]
        }
      ],
      "source": [
        "def run_constrained_experiment(constrained_model:Constrained, \n",
        "                               X, \n",
        "                               y, \n",
        "                               cost_matrix, \n",
        "                               constraint:list, \n",
        "                               random_state=42, \n",
        "                               n_splits=3):\n",
        "\n",
        "    fit_params = {}\n",
        "    out = {}\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    \n",
        "    for (fold, (train_index, test_index)) in enumerate(kf.split(X, y)):\n",
        "        #The ordinary Kfold, but with the constraint\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        if isinstance(constrained_model.model, CostSensitiveDecisionTreeClassifier):\n",
        "            #The Cost Sensitive Decision Tree also needs the cost matrix as a fit parameter\n",
        "            fit_params['cost_mat'] = prepare_for_cost_cle(len(X_train), cost_matrix)\n",
        "\n",
        "        constrained_model.fit(X_train, y_train, **fit_params) #Fitting the model\n",
        "\n",
        "        #The constraint is a float between 0 and 1\n",
        "        y_pred = constrained_model.predict_constrained(X_test, constraint=constraint)\n",
        "        out[fold] = evaluate(y_test, y_pred, cost_matrix)\n",
        "\n",
        "    return pd.DataFrame(out).T.mean(axis=0).to_dict() #Returning the mean of the metrics\n",
        "\n",
        "results = {}\n",
        "for constraint in np.arange(0.00, 0.99, 0.005).round(3):\n",
        "    print(constraint)\n",
        "\n",
        "    partial_results = run_constrained_experiment(Constrained(DecisionTreeClassifier(**dt_best_params)),\n",
        "                                X.values,\n",
        "                                y.values,\n",
        "                                COST_MATRIX,\n",
        "                                constraint=constraint)\n",
        "    results[constraint] = partial_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "6c3861ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(results).T[\"cost\"].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2f31e25f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.41 Effective Threshold: 0.52 Cost False Positive: 7.32 Lower Bound: 6.84 Upper Bound: 7.8125000\n",
            "DONE\n",
            "Threshold: 0.42\n",
            "Effective threshold: 0.42\n",
            "Current cfp:  7.080078125\n",
            "Lower bound:  6.8359375\n",
            "Upper bound:  7.32421875\n",
            "Threshold: 0.49 Effective Threshold: 0.49 Cost False Positive: 8.79 Lower Bound: 7.81 Upper Bound: 9.7722000\n",
            "DONE\n",
            "Threshold: 0.47\n",
            "Effective threshold: 0.47\n",
            "Current cfp:  8.30078125\n",
            "Lower bound:  7.8125\n",
            "Upper bound:  8.7890625\n",
            "Threshold: 0.49 Effective Threshold: 0.49 Cost False Positive: 8.79 Lower Bound: 7.81 Upper Bound: 9.7722000\n",
            "DONE\n",
            "Threshold: 0.47\n",
            "Effective threshold: 0.47\n",
            "Current cfp:  8.30078125\n",
            "Lower bound:  7.8125\n",
            "Upper bound:  8.7890625\n"
          ]
        }
      ],
      "source": [
        "def run_our_experiment(\n",
        "        X, \n",
        "        y, \n",
        "        cost_matrix, \n",
        "        constraint, \n",
        "        random_state=42, \n",
        "        n_splits=3, **model_params):\n",
        "    \n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    cfn = cost_matrix[1,0]\n",
        "    out = {}\n",
        "\n",
        "    for (fold, (train_index, test_index)) in enumerate(kf.split(X, y)):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "        model = ConstrainedCSDecisionTree(constraint=constraint, **model_params)\n",
        "        model.fit(X_train, y_train, cfn=cfn)\n",
        "        y_pred = model.predict(X_test)\n",
        "        out[fold] = evaluate(y_test, y_pred, cost_matrix)\n",
        "\n",
        "    return pd.DataFrame(out).T.mean(axis=0)\n",
        "\n",
        "#ConstrainedCSDecisionTree(constraint=0.5).fit(X_train, y_train, cfn=10)\n",
        "asdasd = run_our_experiment(X.values, y.values, cost_matrix=COST_MATRIX, constraint=0.06702412868632708, **cs_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "940f623b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cost         855.333333\n",
              "accuracy       0.858926\n",
              "precision      0.560000\n",
              "recall         0.251421\n",
              "f1             0.347034\n",
              "dtype: float64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "asdasd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbd6dc6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "d397cd5c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1493 TEST: 747\n",
            "Train: 1493 TEST: 747\n",
            "Train: 1494 TEST: 746\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "cost         774.666667\n",
              "accuracy       0.878572\n",
              "precision      0.706667\n",
              "recall         0.317353\n",
              "f1             0.438003\n",
              "dtype: float64"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constrained_model = Constrained(DecisionTreeClassifier(**dt_best_params))\n",
        "#constrained_model = Constrained(CostSensitiveDecisionTreeClassifier(**cs_best_params))\n",
        "out = run_constrained_experiment(\n",
        "    constrained_model = constrained_model, \n",
        "    X = X.values, \n",
        "    y = y.values, \n",
        "    cost_matrix = COST_MATRIX, \n",
        "    constraint = 0.06702412868632708,#, 0.08042895442359249], \n",
        "    random_state=42, \n",
        "    n_splits=3)\n",
        "\n",
        "# fit_params = {}\n",
        "# fit_params['cost_mat'] = create_cs_matrix(len(X_train), COST_MATRIX)\n",
        "\n",
        "# model.fit(X_train, y_train, **fit_params)\n",
        "\n",
        "# out = {}\n",
        "# for absolute_constraint in range(10, 100, 10):\n",
        "    \n",
        "#     constraint = absolute_constraint/len(y_test) #convert to relative constraint\n",
        "\n",
        "#     y_pred = model.predict_constrained(X_test, constraint=constraint)\n",
        "#     out[absolute_constraint] = evaluate(y_test, y_pred, COST_MATRIX)\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "4312c34f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cost         774.666667\n",
              "accuracy       0.878572\n",
              "precision      0.706667\n",
              "recall         0.317353\n",
              "f1             0.438003\n",
              "dtype: float64"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "f6d8884c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cost</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1060.0</td>\n",
              "      <td>0.809906</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.089286</td>\n",
              "      <td>0.123457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1017.0</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.117117</td>\n",
              "      <td>0.161491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1050.0</td>\n",
              "      <td>0.810992</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.090090</td>\n",
              "      <td>0.124224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cost  accuracy  precision    recall        f1\n",
              "0  1060.0  0.809906       0.20  0.089286  0.123457\n",
              "1  1017.0  0.819277       0.26  0.117117  0.161491\n",
              "2  1050.0  0.810992       0.20  0.090090  0.124224"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(out[0.06702412868632708]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "0ec6c331",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.067024</th>\n",
              "      <th>0.080429</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cost</th>\n",
              "      <td>1042.333333</td>\n",
              "      <td>1034.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.813392</td>\n",
              "      <td>0.804464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.211111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.098831</td>\n",
              "      <td>0.113819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>0.136390</td>\n",
              "      <td>0.147899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0.067024     0.080429\n",
              "cost       1042.333333  1034.000000\n",
              "accuracy      0.813392     0.804464\n",
              "precision     0.220000     0.211111\n",
              "recall        0.098831     0.113819\n",
              "f1            0.136390     0.147899"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({constraint: pd.DataFrame(out[constraint]).mean(axis=1).to_dict() for constraint in out.keys()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "a863a53c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0.1: {'cost': 441.4,\n",
              "  'accuracy': 0.8625,\n",
              "  'precision': 0.5590909090909091,\n",
              "  'recall': 0.3681592039800995,\n",
              "  'f1': 0.443963963963964},\n",
              " 0.2: {'cost': 365.4,\n",
              "  'accuracy': 0.8111607142857142,\n",
              "  'precision': 0.39999999999999997,\n",
              "  'recall': 0.5327453640886477,\n",
              "  'f1': 0.4569230769230769},\n",
              " 0.3: {'cost': 289.4,\n",
              "  'accuracy': 0.7598214285714285,\n",
              "  'precision': 0.34776119402985073,\n",
              "  'recall': 0.697467209407508,\n",
              "  'f1': 0.46410945273631843},\n",
              " 0.4: {'cost': 283.8,\n",
              "  'accuracy': 0.6799107142857143,\n",
              "  'precision': 0.28603351955307266,\n",
              "  'recall': 0.7666214382632294,\n",
              "  'f1': 0.416618549858968},\n",
              " 0.5: {'cost': 302.4,\n",
              "  'accuracy': 0.5901785714285714,\n",
              "  'precision': 0.23928571428571427,\n",
              "  'recall': 0.8025780189959294,\n",
              "  'f1': 0.3686550539163408}}"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{constraint: pd.DataFrame(out[constraint]).mean(axis=1).to_dict() for constraint in out.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "eeb4c123",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cost         443.600000\n",
              "accuracy       0.861607\n",
              "precision      0.554545\n",
              "recall         0.365174\n",
              "f1             0.440360\n",
              "dtype: float64"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(out[0.1]).mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "c9e6a7d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.1</th>\n",
              "      <td>{'cost': 776, 'accuracy': 0.8527443105756358, ...</td>\n",
              "      <td>{'cost': 711, 'accuracy': 0.8674698795180723, ...</td>\n",
              "      <td>{'cost': 766, 'accuracy': 0.853887399463807, '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.2</th>\n",
              "      <td>{'cost': 587, 'accuracy': 0.8165997322623829, ...</td>\n",
              "      <td>{'cost': 632, 'accuracy': 0.8045515394912985, ...</td>\n",
              "      <td>{'cost': 610, 'accuracy': 0.8096514745308311, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.3</th>\n",
              "      <td>{'cost': 508, 'accuracy': 0.7536813922356091, ...</td>\n",
              "      <td>{'cost': 487, 'accuracy': 0.7576974564926372, ...</td>\n",
              "      <td>{'cost': 486, 'accuracy': 0.7587131367292225, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.4</th>\n",
              "      <td>{'cost': 538, 'accuracy': 0.6653279785809906, ...</td>\n",
              "      <td>{'cost': 484, 'accuracy': 0.677376171352075, '...</td>\n",
              "      <td>{'cost': 484, 'accuracy': 0.6769436997319035, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.5</th>\n",
              "      <td>{'cost': 558, 'accuracy': 0.5783132530120482, ...</td>\n",
              "      <td>{'cost': 515, 'accuracy': 0.5876840696117804, ...</td>\n",
              "      <td>{'cost': 493, 'accuracy': 0.5924932975871313, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0  \\\n",
              "0.1  {'cost': 776, 'accuracy': 0.8527443105756358, ...   \n",
              "0.2  {'cost': 587, 'accuracy': 0.8165997322623829, ...   \n",
              "0.3  {'cost': 508, 'accuracy': 0.7536813922356091, ...   \n",
              "0.4  {'cost': 538, 'accuracy': 0.6653279785809906, ...   \n",
              "0.5  {'cost': 558, 'accuracy': 0.5783132530120482, ...   \n",
              "\n",
              "                                                     1  \\\n",
              "0.1  {'cost': 711, 'accuracy': 0.8674698795180723, ...   \n",
              "0.2  {'cost': 632, 'accuracy': 0.8045515394912985, ...   \n",
              "0.3  {'cost': 487, 'accuracy': 0.7576974564926372, ...   \n",
              "0.4  {'cost': 484, 'accuracy': 0.677376171352075, '...   \n",
              "0.5  {'cost': 515, 'accuracy': 0.5876840696117804, ...   \n",
              "\n",
              "                                                     2  \n",
              "0.1  {'cost': 766, 'accuracy': 0.853887399463807, '...  \n",
              "0.2  {'cost': 610, 'accuracy': 0.8096514745308311, ...  \n",
              "0.3  {'cost': 486, 'accuracy': 0.7587131367292225, ...  \n",
              "0.4  {'cost': 484, 'accuracy': 0.6769436997319035, ...  \n",
              "0.5  {'cost': 493, 'accuracy': 0.5924932975871313, ...  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#pd.json_normalize(out)\n",
        "\n",
        "pd.DataFrame(out).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "4d71db69",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mInit signature:\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mSource:\u001b[0m        \n",
            "\u001b[1;32mclass\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[1;34m\"\"\"Stratified K-Folds cross-validator.\n",
            "\n",
            "    Provides train/test indices to split data in train/test sets.\n",
            "\n",
            "    This cross-validation object is a variation of KFold that returns\n",
            "    stratified folds. The folds are made by preserving the percentage of\n",
            "    samples for each class.\n",
            "\n",
            "    Read more in the :ref:`User Guide <stratified_k_fold>`.\n",
            "\n",
            "    For visualisation of cross-validation behaviour and\n",
            "    comparison between common scikit-learn split methods\n",
            "    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    n_splits : int, default=5\n",
            "        Number of folds. Must be at least 2.\n",
            "\n",
            "        .. versionchanged:: 0.22\n",
            "            ``n_splits`` default value changed from 3 to 5.\n",
            "\n",
            "    shuffle : bool, default=False\n",
            "        Whether to shuffle each class's samples before splitting into batches.\n",
            "        Note that the samples within each split will not be shuffled.\n",
            "\n",
            "    random_state : int, RandomState instance or None, default=None\n",
            "        When `shuffle` is True, `random_state` affects the ordering of the\n",
            "        indices, which controls the randomness of each fold for each class.\n",
            "        Otherwise, leave `random_state` as `None`.\n",
            "        Pass an int for reproducible output across multiple function calls.\n",
            "        See :term:`Glossary <random_state>`.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    >>> import numpy as np\n",
            "    >>> from sklearn.model_selection import StratifiedKFold\n",
            "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
            "    >>> y = np.array([0, 0, 1, 1])\n",
            "    >>> skf = StratifiedKFold(n_splits=2)\n",
            "    >>> skf.get_n_splits(X, y)\n",
            "    2\n",
            "    >>> print(skf)\n",
            "    StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
            "    >>> for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
            "    ...     print(f\"Fold {i}:\")\n",
            "    ...     print(f\"  Train: index={train_index}\")\n",
            "    ...     print(f\"  Test:  index={test_index}\")\n",
            "    Fold 0:\n",
            "      Train: index=[1 3]\n",
            "      Test:  index=[0 2]\n",
            "    Fold 1:\n",
            "      Train: index=[0 2]\n",
            "      Test:  index=[1 3]\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "    The implementation is designed to:\n",
            "\n",
            "    * Generate test sets such that all contain the same distribution of\n",
            "      classes, or as close as possible.\n",
            "    * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
            "      ``y = [1, 0]`` should not change the indices generated.\n",
            "    * Preserve order dependencies in the dataset ordering, when\n",
            "      ``shuffle=False``: all samples from class k in some test set were\n",
            "      contiguous in y, or separated in y by samples from classes other than k.\n",
            "    * Generate test sets where the smallest and largest differ by at most one\n",
            "      sample.\n",
            "\n",
            "    .. versionchanged:: 0.22\n",
            "        The previous implementation did not follow the last constraint.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.\n",
            "    \"\"\"\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mrng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mtype_of_target_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mallowed_target_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;34m\"Supported target types are: {}. Got {!r} instead.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                    \u001b[0mallowed_target_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_of_target_y\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# y_inv encodes y according to lexicographic order. We invert y_idx to\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# map the classes so that they are encoded by order of appearance:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# 0 represents the first label appearing in y, 1 the second, etc.\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_perm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_perm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_inv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mmin_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;34m\" number of members in each class.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;34m\"The least populated class in y has only %d\"\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;34m\" members, which is less than n_splits=%d.\"\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmin_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[0mUserWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# Determine the optimal number of samples from each class in each fold,\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# using round robin over the sorted y. (This can be done direct from\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# counts, but that code is unreadable.)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mallocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_order\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# To maintain the data order dependencies as best as possible within\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# the stratification constraint, we assign samples from each class in\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;31m# blocks (and then mess that up when shuffle=True).\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;31m# since the kth column of allocation stores the number of samples\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;31m# of class k in each test set, this generates blocks of fold\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;31m# indices corresponding to the allocation for class k.\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[0mfolds_for_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallocation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m                \u001b[0mrng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds_for_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_encoded\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolds_for_class\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\n",
            "\u001b[0m\u001b[1;33m\n",
            "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;34m\"\"\"Generate indices to split data into training and test set.\n",
            "\n",
            "        Parameters\n",
            "        ----------\n",
            "        X : array-like of shape (n_samples, n_features)\n",
            "            Training data, where `n_samples` is the number of samples\n",
            "            and `n_features` is the number of features.\n",
            "\n",
            "            Note that providing ``y`` is sufficient to generate the splits and\n",
            "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
            "            ``X`` instead of actual training data.\n",
            "\n",
            "        y : array-like of shape (n_samples,)\n",
            "            The target variable for supervised learning problems.\n",
            "            Stratification is done based on the y labels.\n",
            "\n",
            "        groups : object\n",
            "            Always ignored, exists for compatibility.\n",
            "\n",
            "        Yields\n",
            "        ------\n",
            "        train : ndarray\n",
            "            The training set indices for that split.\n",
            "\n",
            "        test : ndarray\n",
            "            The testing set indices for that split.\n",
            "\n",
            "        Notes\n",
            "        -----\n",
            "        Randomized CV splitters may return different results for each call of\n",
            "        split. You can make the results identical by setting `random_state`\n",
            "        to an integer.\n",
            "        \"\"\"\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
            "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFile:\u001b[0m           c:\\users\\imargolin\\anaconda3\\envs\\ucp\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
            "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
            "\u001b[1;31mSubclasses:\u001b[0m     "
          ]
        }
      ],
      "source": [
        "StratifiedKFold??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80c7439",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_constrained_experiment(clf:Constrained, X, y, cost_matrix, constraint, random_state=42):\n",
        "\n",
        "    fit_params = {}\n",
        "    out = []\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "    #kf.get_n_splits(X)\n",
        "    for (train_index, test_index) in kf.split(X, y):\n",
        "        print(\"Train:\", len(train_index), \"TEST:\", len(test_index))\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        if isinstance(clf, CostSensitiveDecisionTreeClassifier):\n",
        "            #If type of CostSensitiveDecisionTreeClassifier, then create a cost matrix for the training set\n",
        "            fit_params['cost_mat'] = prepare_for_cost_cle(len(X_train), cost_matrix)\n",
        "\n",
        "        clf.fit(X_train, y_train, **fit_params) \n",
        "        y_pred_proba = clf.predict_proba(X_test)[:, 1] #get the probability of the positive class\n",
        "\n",
        "        if constraint:\n",
        "            y_pred = prediction_up_to_constraint(y_pred_proba, constraint) \n",
        "        else:\n",
        "            y_pred = clf.predict(X_test)\n",
        "        \n",
        "        out.append(evaluate(y_test, y_pred, cost_matrix))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "5ec36bc6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cost</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1039.0</td>\n",
              "      <td>0.849866</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.017544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1049.0</td>\n",
              "      <td>0.836461</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.016129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1048.0</td>\n",
              "      <td>0.825737</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.029851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1058.0</td>\n",
              "      <td>0.812332</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1068.0</td>\n",
              "      <td>0.798928</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.025974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1067.0</td>\n",
              "      <td>0.788204</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.028846</td>\n",
              "      <td>0.036585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1055.0</td>\n",
              "      <td>0.780161</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.048077</td>\n",
              "      <td>0.057471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1054.0</td>\n",
              "      <td>0.769437</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.065217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>1042.0</td>\n",
              "      <td>0.761394</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.082474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cost  accuracy  precision    recall        f1\n",
              "10  1039.0  0.849866   0.100000  0.009615  0.017544\n",
              "20  1049.0  0.836461   0.050000  0.009615  0.016129\n",
              "30  1048.0  0.825737   0.066667  0.019231  0.029851\n",
              "40  1058.0  0.812332   0.050000  0.019231  0.027778\n",
              "50  1068.0  0.798928   0.040000  0.019231  0.025974\n",
              "60  1067.0  0.788204   0.050000  0.028846  0.036585\n",
              "70  1055.0  0.780161   0.071429  0.048077  0.057471\n",
              "80  1054.0  0.769437   0.075000  0.057692  0.065217\n",
              "90  1042.0  0.761394   0.088889  0.076923  0.082474"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(out).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "95285d14",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ConstrainedClassifier(constraint=0.0938337801608579,\n",
              "                      model=CostSensitiveDecisionTreeClassifier(max_depth=5,\n",
              "                                                                min_samples_leaf=15))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ConstrainedClassifier</label><div class=\"sk-toggleable__content\"><pre>ConstrainedClassifier(constraint=0.0938337801608579,\n",
              "                      model=CostSensitiveDecisionTreeClassifier(max_depth=5,\n",
              "                                                                min_samples_leaf=15))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: CostSensitiveDecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>CostSensitiveDecisionTreeClassifier(max_depth=5, min_samples_leaf=15)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CostSensitiveDecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>CostSensitiveDecisionTreeClassifier(max_depth=5, min_samples_leaf=15)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "ConstrainedClassifier(constraint=0.0938337801608579,\n",
              "                      model=CostSensitiveDecisionTreeClassifier(max_depth=5,\n",
              "                                                                min_samples_leaf=15))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cs_dt = ConstrainedClassifier(CostSensitiveDecisionTreeClassifier(**cs_best_params), constraint=constraint)\n",
        "cs_dt.fit(X_train, y_train, cost_mat = prepare_for_cost_cle(len(X_train), COST_MATRIX))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "fa7c1273",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cs_dt.predict_constrained(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8595dda5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7bef91",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0668a83d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "93181596",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt.prediction_up_to_constraint(X_test).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "3118880e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "line2\n"
          ]
        }
      ],
      "source": [
        "print(\"line1\", end = \"\\r\")\n",
        "print(\"line2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "bb3fb09c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "3f9178aa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.33 Effective Threshold: 0.46 Cost False Positive: 50.290\n",
            "DONE\n",
            "Threshold: 0.33\n",
            "Effective threshold: 0.33\n",
            "Current cfp:  50.048828125\n",
            "Lower bound:  49.8046875\n",
            "Upper bound:  50.29296875\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ConstrainedCSDecisionTree(constraint=0.11160714285714286, num_iterations=60)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ConstrainedCSDecisionTree</label><div class=\"sk-toggleable__content\"><pre>ConstrainedCSDecisionTree(constraint=0.11160714285714286, num_iterations=60)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "ConstrainedCSDecisionTree(constraint=0.11160714285714286, num_iterations=60)"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ccsdt = ConstrainedCSDecisionTree(num_iterations=60, constraint=constraint, **cs_best_params)\n",
        "ccsdt.fit(X_train, y_train, cfn= COST_FALSE_NEGATIVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "07032d38",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = ccsdt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61159f16",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "c058f58d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cost': 4224,\n",
              " 'accuracy': 0.8526785714285714,\n",
              " 'precision': 0.52,\n",
              " 'recall': 0.38235294117647056,\n",
              " 'f1': 0.4406779661016949}"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(y_test, y_pred, COST_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b511a685",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method CostSensitiveDecisionTreeClassifier.predict_proba of CostSensitiveDecisionTreeClassifier(max_depth=5, min_samples_leaf=15)>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ccsdt.best_model.predict_proba(X_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "e8365366",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.11607142857142858"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buga = ccsdt.best_model.predict_proba(X_test)[:,1]\n",
        "t = 50/(50+COST_FALSE_NEGATIVE)\n",
        "(buga > t).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "4e96d2f2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_predict = ccsdt.best_model.predict_proba(X_test)[:,1] > t\n",
        "my_predict = my_predict.astype(int)\n",
        "\n",
        "ccsdt.best_model.predict(X_test) == my_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "15b03da0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "269    0.630435\n",
              "298    0.630435\n",
              "62     0.630435\n",
              "187    0.630435\n",
              "289    0.630435\n",
              "221    0.630435\n",
              "282    0.630435\n",
              "181    0.630435\n",
              "293    0.630435\n",
              "420    0.630435\n",
              "86     0.630435\n",
              "33     0.630435\n",
              "253    0.630435\n",
              "61     0.630435\n",
              "367    0.630435\n",
              "365    0.630435\n",
              "277    0.630435\n",
              "36     0.630435\n",
              "235    0.630435\n",
              "113    0.630435\n",
              "317    0.630435\n",
              "38     0.630435\n",
              "410    0.630435\n",
              "142    0.630435\n",
              "141    0.630435\n",
              "398    0.524272\n",
              "57     0.524272\n",
              "274    0.524272\n",
              "200    0.524272\n",
              "224    0.524272\n",
              "77     0.524272\n",
              "209    0.524272\n",
              "295    0.524272\n",
              "375    0.524272\n",
              "300    0.524272\n",
              "165    0.524272\n",
              "311    0.524272\n",
              "119    0.524272\n",
              "120    0.524272\n",
              "342    0.524272\n",
              "dtype: float64"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buga.nlargest(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "82169f9a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33     0.630435\n",
              "36     0.630435\n",
              "38     0.630435\n",
              "61     0.630435\n",
              "62     0.630435\n",
              "86     0.630435\n",
              "113    0.630435\n",
              "141    0.630435\n",
              "142    0.630435\n",
              "181    0.630435\n",
              "187    0.630435\n",
              "221    0.630435\n",
              "235    0.630435\n",
              "253    0.630435\n",
              "269    0.630435\n",
              "277    0.630435\n",
              "282    0.630435\n",
              "289    0.630435\n",
              "293    0.630435\n",
              "298    0.630435\n",
              "317    0.630435\n",
              "365    0.630435\n",
              "367    0.630435\n",
              "410    0.630435\n",
              "420    0.630435\n",
              "3      0.524272\n",
              "6      0.524272\n",
              "20     0.524272\n",
              "34     0.524272\n",
              "57     0.524272\n",
              "77     0.524272\n",
              "119    0.524272\n",
              "120    0.524272\n",
              "165    0.524272\n",
              "189    0.524272\n",
              "200    0.524272\n",
              "209    0.524272\n",
              "224    0.524272\n",
              "230    0.524272\n",
              "240    0.524272\n",
              "dtype: float64"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buga = ccsdt.best_model.predict_proba(X_test)[:, 1]\n",
        "buga = pd.Series(buga)\n",
        "\n",
        "buga.nlargest(40)\n",
        "\n",
        "# buga.iloc[:52].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "25b79be8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ccsdt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86ace54",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5a8daf",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58618def",
      "metadata": {},
      "outputs": [],
      "source": [
        "buga = CostSensitiveDecisionTreeClassifier(**cs_best_params)\n",
        "\n",
        "cost_mat_train = prepare_for_cost_cle(len(X), np.array([[0, 1], [1000, 0]]))\n",
        "cost_mat_train\n",
        "\n",
        "buga.fit(X.values, y.values, cost_mat=cost_mat_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5eb037a",
      "metadata": {},
      "outputs": [],
      "source": [
        "buga.predict(X.values).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ed3028",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = buga.predict_proba(X.values)[:, 1]\n",
        "ax = pd.cut(pd.Series(y_pred), bins = np.linspace(0,1,11)).value_counts(normalize=True).plot.bar(grid=True)\n",
        "ax.set_ylabel('Percentage of samples')\n",
        "ax.set_yticks(np.linspace(0, 1, 11))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "544c9d5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.Series().plot.hist(bins=np.linspace(0,1,11), density=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df85007b",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_cs_dt = CostSensitiveDecisionTreeClassifier()\n",
        "clf_cs_dt.set_params(**cs_best_params)\n",
        "\n",
        "clf_dt = DecisionTreeClassifier()\n",
        "clf_dt.set_params(**dt_best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f90b729",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_dt.fit(X, y)\n",
        "y_pred = clf_dt.predict_proba(X)[:, 1]\n",
        "y_pred = prediction_up_to_constraint(y_pred, 3000)\n",
        "evaluate(y, y_pred, COST_MATRIX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c2d3f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bad5f7c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a67d400",
      "metadata": {},
      "outputs": [],
      "source": [
        "# buga = full_experiment(\n",
        "#     clf=clf_cs_dt, \n",
        "#     random_state=42, \n",
        "#     X=X.values, \n",
        "#     y=y.values, \n",
        "#     cost_matrix=COST_MATRIX, \n",
        "#     constraint=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76a397f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2873182c",
      "metadata": {},
      "outputs": [],
      "source": [
        "classfication_report_with_cost(y, y_pred, COST_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d01767f",
      "metadata": {},
      "outputs": [],
      "source": [
        "classfication_report_with_cost(y, y_pred, COST_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3086a058",
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "50715aa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "buga = prepare_for_cost_cle(len(y), COST_MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd73787",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_cs_dt.fit(X.values, y.values, buga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e19258e",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_cs_dt.predict_proba(X.values)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c315c2b",
      "metadata": {
        "id": "0c315c2b",
        "outputId": "6b56ecdb-c4ea-49de-cab6-3a77f86a995a"
      },
      "outputs": [],
      "source": [
        "X = df.drop(labels = 'Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# drop columns\n",
        "worst_features =[]\n",
        "for i,v in enumerate(mutual_info):\n",
        "    if v in sorted(mutual_info)[:17]: # update to 0.75*num_of_features\n",
        "        worst_features.append(i)\n",
        "print(worst_features)\n",
        "X_17 = X.iloc[:, worst_features]\n",
        "X_17 = X_17.to_numpy()\n",
        "\n",
        "worst_features =[]\n",
        "for i,v in enumerate(mutual_info):\n",
        "    if v in sorted(mutual_info)[:11]: # update to 0.5*num_of_features\n",
        "        worst_features.append(i)\n",
        "print(worst_features)\n",
        "X_11 = X.iloc[:, worst_features]\n",
        "X_11 = X_11.to_numpy()\n",
        "\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "r = y*cfn +(1-y)*(-cfp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829a1887",
      "metadata": {},
      "outputs": [],
      "source": [
        "y*COST_FALSE_NEGATIVE + (1-y)*(-COST_FALSE_POSITIVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8b94091c",
      "metadata": {
        "id": "8b94091c"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# cost_mat_train_i = cost_mat(1,10,y_train)\n",
        "# clf_cs_dt.fit(np.array(X_train),np.array(y_train), cost_mat_train_i)\n",
        "# y_pred_proba_i= clf_cs_dt.predict_proba(np.array(X_train))\n",
        "# y_pred_probs_i = [y_pred_proba_i[j][1] for j in range(len(y_pred_proba_i))]\n",
        "# d_t_i = get_dynamic_threshold(y_pred_probs_i,100,0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecda30f",
      "metadata": {
        "id": "4ecda30f",
        "outputId": "b24bc1a5-3118-45cc-e936-fd22447c058b"
      },
      "outputs": [],
      "source": [
        "#apply the experimnt on differnt slices of the dataset\n",
        "clf_cs_dt = CostSensitiveDecisionTreeClassifier(min_samples_leaf = best_combination[0], max_depth = best_combination[1],\n",
        "                                              pruned = best_combination[2], min_gain = best_combination[3])\n",
        "\n",
        "# for smoozing the graph - repeat the experiment with 10 different CV\n",
        "random_state_list = [24]#, 6, 18, 32, 76, 5, 40, 12, 31, 9]\n",
        "constraint = [50, 60]\n",
        "result_dict_all, result_dict_075, result_dict_05 = {}, {}, {}\n",
        "for random_state in random_state_list:\n",
        "    print('********', random_state, '********')\n",
        "\n",
        "    fold_dict_all = experiment(clf_cs_dt, clf_dt, random_state, X, y, cfp, cfn, constraint)\n",
        "    result_dict_all[random_state] = fold_dict_all\n",
        "\n",
        "#     fold_dict_075 = experiment(clf, clf_dt, random_state, X_17, y, r, cfp, cfn, constraint)\n",
        "#     result_dict_075[random_state] = fold_dict_075\n",
        "\n",
        "#     fold_dict_05 = experiment(clf, clf_dt, random_state, X_11, y, r, cfp, cfn, constraint)\n",
        "#     result_dict_05[random_state] = fold_dict_05\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f4c9ef2",
      "metadata": {
        "id": "6f4c9ef2"
      },
      "outputs": [],
      "source": [
        "# #save data\n",
        "# with open('result_dict_05.pickle', 'wb') as handle:\n",
        "#     pickle.dump(result_dict_05, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('result_dict_075.pickle', 'wb') as handle:\n",
        "#     pickle.dump(result_dict_075, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('result_dict_all.pickle', 'wb') as handle:\n",
        "#     pickle.dump(result_dict_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74dd72ae",
      "metadata": {
        "id": "74dd72ae"
      },
      "outputs": [],
      "source": [
        "# #load data\n",
        "# #random_state_list = [24, 6, 18, 32, 76, 5, 40, 12, 31, 9]\n",
        "\n",
        "# with open('marketing_result_dict_11_v2.pickle', 'rb') as handle:\n",
        "#     marketing_result_dict_11 = pickle.load(handle)\n",
        "\n",
        "# with open('marketing_result_dict_17_v2.pickle', 'rb') as handle:\n",
        "#     marketing_result_dict_17 = pickle.load(handle)\n",
        "\n",
        "# with open('marketing_result_dict_all_v2.pickle', 'rb') as handle:\n",
        "#     marketing_result_dict_all = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d763c397",
      "metadata": {},
      "outputs": [],
      "source": [
        "result_dict_all[24][1][\"cs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2316dc8f",
      "metadata": {
        "id": "2316dc8f",
        "outputId": "45d03fe3-db90-4ea3-d2a8-39bd8773a427",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(result_dict_all[24][1]['cs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e68df14",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(result_dict_all[24][1][\"optimal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bad51c5f",
      "metadata": {
        "id": "bad51c5f"
      },
      "outputs": [],
      "source": [
        "cs_measure, dt_measure, one_before_measure, itr_list = get_measure_list(result_dict_all, 'cost', random_state_list, constraint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1d2954",
      "metadata": {},
      "outputs": [],
      "source": [
        "one_before_measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7df6027",
      "metadata": {
        "id": "b7df6027",
        "outputId": "ea6696ac-b5c8-4b35-b213-98f2f2e7337b",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plt.plot(constraint, get_mean_list(one_before_measure), label = 'AdaCSL-WRC')\n",
        "plt.plot(constraint, get_mean_list(cs_measure), label = 'CS-DT')\n",
        "plt.plot(constraint, get_mean_list(dt_measure), label = 'DT')\n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('Constraint')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b3b73d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#create conda env\n",
        "#conda create --name AdaCSL_WRC python=3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b90e89f",
      "metadata": {
        "id": "9b90e89f",
        "outputId": "b701e239-6aa8-4b99-ced2-d75ac1e32a98"
      },
      "outputs": [],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66877a00",
      "metadata": {
        "id": "66877a00"
      },
      "outputs": [],
      "source": [
        "!pip freeze"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
