{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a21ab2b",
   "metadata": {},
   "source": [
    "# Adaptive Cost Sensitive Trees Expriment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b45d9",
   "metadata": {},
   "source": [
    "## imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba295ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ada_csl_wrc.utils\n"
     ]
    }
   ],
   "source": [
    "from ada_csl_wrc.evaluation import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ada_csl_wrc.models import CostSensitiveDecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from ada_csl_wrc.models import ConstrainedCSDecisionTree\n",
    "from ada_csl_wrc.models import Constrained\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ada_csl_wrc.utils import prediction_up_to_constraint\n",
    "from ada_csl_wrc.utils import prepare_for_cost_cle\n",
    "from ada_csl_wrc.utils import filter_only_worst_features\n",
    "from ada_csl_wrc.utils import find_effective_threshold\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import numbers\n",
    "from sklearn.utils import check_random_state, column_or_1d\n",
    "from six import with_metaclass\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.ensemble import BaseEnsemble\n",
    "from sklearn.base import ClassifierMixin\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import itertools\n",
    "\n",
    "from timeit import default_timer\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005ac74",
   "metadata": {},
   "source": [
    "## Random Forest Cost Sensitive Model Code \n",
    "### copied from https://github.com/albahnsen/CostSensitiveClassification/tree/master/costcla/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed1e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savings_score(y_true, y_pred, cost_mat):\n",
    "    #TODO: update description\n",
    "    \"\"\"Savings score.\n",
    "\n",
    "    This function calculates the savings cost of using y_pred on y_true with\n",
    "    cost-matrix cost-mat, as the difference of y_pred and the cost_loss of a naive\n",
    "    classification model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like or label indicator matrix\n",
    "        Ground truth (correct) labels.\n",
    "\n",
    "    y_pred : array-like or label indicator matrix\n",
    "        Predicted labels, as returned by a classifier.\n",
    "\n",
    "    cost_mat : array-like of shape = [n_samples, 4]\n",
    "        Cost matrix of the classification problem\n",
    "        Where the columns represents the costs of: false positives, false negatives,\n",
    "        true positives and true negatives, for each example.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        Savings of a using y_pred on y_true with cost-matrix cost-mat\n",
    "\n",
    "        The best performance is 1.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Correa Bahnsen, A. Stojanovic, D.Aouada, B, Ottersten,\n",
    "           `\"Improving Credit Card Fraud Detection with Calibrated Probabilities\" <http://albahnsen.com/files/%20Improving%20Credit%20Card%20Fraud%20Detection%20by%20using%20Calibrated%20Probabilities%20-%20Publish.pdf>`__, in Proceedings of the fourteenth SIAM International Conference on Data Mining,\n",
    "           677-685, 2014.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    cost_loss\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from costcla.metrics import savings_score, cost_loss\n",
    "    >>> y_pred = [0, 1, 0, 0]\n",
    "    >>> y_true = [0, 1, 1, 0]\n",
    "    >>> cost_mat = np.array([[4, 1, 0, 0], [1, 3, 0, 0], [2, 3, 0, 0], [2, 1, 0, 0]])\n",
    "    >>> savings_score(y_true, y_pred, cost_mat)\n",
    "    0.5\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: Check consistency of cost_mat\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_pred = column_or_1d(y_pred)\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    # Calculate the cost of naive prediction\n",
    "    cost_base = min(cost_loss(y_true, np.zeros(n_samples), cost_mat),\n",
    "                    cost_loss(y_true, np.ones(n_samples), cost_mat))\n",
    "\n",
    "    cost = cost_loss(y_true, y_pred, cost_mat)\n",
    "    return 1.0 - cost / cost_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11f95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_loss(y_true, y_pred, cost_mat):\n",
    "    #TODO: update description\n",
    "    \"\"\"Cost classification loss.\n",
    "\n",
    "    This function calculates the cost of using y_pred on y_true with\n",
    "    cost-matrix cost-mat. It differ from traditional classification evaluation\n",
    "    measures since measures such as accuracy asing the same cost to different\n",
    "    errors, but that is not the real case in several real-world classification\n",
    "    problems as they are example-dependent cost-sensitive in nature, where the\n",
    "    costs due to misclassification vary between examples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like or label indicator matrix\n",
    "        Ground truth (correct) labels.\n",
    "\n",
    "    y_pred : array-like or label indicator matrix\n",
    "        Predicted labels, as returned by a classifier.\n",
    "\n",
    "    cost_mat : array-like of shape = [n_samples, 4]\n",
    "        Cost matrix of the classification problem\n",
    "        Where the columns represents the costs of: false positives, false negatives,\n",
    "        true positives and true negatives, for each example.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        Cost of a using y_pred on y_true with cost-matrix cost-mat\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] C. Elkan, \"The foundations of Cost-Sensitive Learning\",\n",
    "           in Seventeenth International Joint Conference on Artificial Intelligence,\n",
    "           973-978, 2001.\n",
    "\n",
    "    .. [2] A. Correa Bahnsen, A. Stojanovic, D.Aouada, B, Ottersten,\n",
    "           `\"Improving Credit Card Fraud Detection with Calibrated Probabilities\" <http://albahnsen.com/files/%20Improving%20Credit%20Card%20Fraud%20Detection%20by%20using%20Calibrated%20Probabilities%20-%20Publish.pdf>`__, in Proceedings of the fourteenth SIAM International Conference on Data Mining,\n",
    "           677-685, 2014.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    savings_score\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from costcla.metrics import cost_loss\n",
    "    >>> y_pred = [0, 1, 0, 0]\n",
    "    >>> y_true = [0, 1, 1, 0]\n",
    "    >>> cost_mat = np.array([[4, 1, 0, 0], [1, 3, 0, 0], [2, 3, 0, 0], [2, 1, 0, 0]])\n",
    "    >>> cost_loss(y_true, y_pred, cost_mat)\n",
    "    3\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: Check consistency of cost_mat\n",
    "\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_true = (y_true == 1).astype(np.float32)\n",
    "    y_pred = column_or_1d(y_pred)\n",
    "    y_pred = (y_pred == 1).astype(np.float32)\n",
    "    cost = y_true * ((1 - y_pred) * cost_mat[:, 1] + y_pred * cost_mat[:, 2])\n",
    "    cost += (1 - y_true) * (y_pred * cost_mat[:, 0] + (1 - y_pred) * cost_mat[:, 3])\n",
    "    return np.sum(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00e2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INT = np.iinfo(np.int32).max\n",
    "class BaseBagging(with_metaclass(ABCMeta, BaseEnsemble)):\n",
    "    \"\"\"Base class for Bagging meta-estimator.\n",
    "\n",
    "    Warning: This class should not be used directly. Use derived classes\n",
    "    instead.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 base_estimator=None,\n",
    "                 n_estimators=10,\n",
    "                 max_samples=1.0,\n",
    "                 max_features=1.0,\n",
    "                 bootstrap=True,\n",
    "                 bootstrap_features=False,\n",
    "                 combination='majority_voting',\n",
    "                 n_jobs=1,\n",
    "                 random_state=None,\n",
    "                 verbose=0):\n",
    "        super(BaseBagging, self).__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators)\n",
    "\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.bootstrap_features = bootstrap_features\n",
    "        self.combination = combination\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y, cost_mat, sample_weight=None):\n",
    "        \"\"\"Build a Bagging ensemble of estimators from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrices are accepted only if\n",
    "            they are supported by the base estimator.\n",
    "\n",
    "        y : array-like, shape = [n_samples]\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "\n",
    "        cost_mat : array-like of shape = [n_samples, 4]\n",
    "            Cost matrix of the classification problem\n",
    "            Where the columns represents the costs of: false positives, false negatives,\n",
    "            true positives and true negatives, for each example.\n",
    "\n",
    "        sample_weight : array-like, shape = [n_samples] or None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Note that this is supported only if the base estimator supports\n",
    "            sample weighting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        # Convert data\n",
    "        # X, y = check_X_y(X, y, ['csr', 'csc', 'coo'])  # Not in sklearn verion 0.15\n",
    "\n",
    "        # Remap output\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        y = self._validate_y(y)\n",
    "\n",
    "        # Check parameters\n",
    "        self._validate_estimator()\n",
    "\n",
    "        if isinstance(self.max_samples, (numbers.Integral, np.integer)):\n",
    "            max_samples = self.max_samples\n",
    "        else:  # float\n",
    "            max_samples = int(self.max_samples * X.shape[0])\n",
    "\n",
    "        if not (0 < max_samples <= X.shape[0]):\n",
    "            raise ValueError(\"max_samples must be in (0, n_samples]\")\n",
    "\n",
    "        if isinstance(self.max_features, (numbers.Integral, np.integer)):\n",
    "            max_features = self.max_features\n",
    "        else:  # float\n",
    "            max_features = int(self.max_features * self.n_features_)\n",
    "\n",
    "        if not (0 < max_features <= self.n_features_):\n",
    "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
    "\n",
    "        # Free allocated memory, if any\n",
    "        self.estimators_ = None\n",
    "\n",
    "        # Parallel loop\n",
    "        n_jobs, n_estimators, starts = _partition_estimators(self.n_estimators,\n",
    "                                                             self.n_jobs)\n",
    "        \n",
    "        seeds = random_state.randint(MAX_INT, size=self.n_estimators)\n",
    "\n",
    "        all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
    "            delayed(_parallel_build_estimators)(\n",
    "                n_estimators[i],\n",
    "                self,\n",
    "                X,\n",
    "                y,\n",
    "                cost_mat,\n",
    "                seeds[starts[i]:starts[i + 1]],\n",
    "                verbose=self.verbose)\n",
    "            for i in range(n_jobs))\n",
    "\n",
    "        # Reduce\n",
    "        self.estimators_ = list(itertools.chain.from_iterable(\n",
    "            t[0] for t in all_results))\n",
    "        self.estimators_samples_ = list(itertools.chain.from_iterable(\n",
    "            t[1] for t in all_results))\n",
    "        self.estimators_features_ = list(itertools.chain.from_iterable(\n",
    "            t[2] for t in all_results))\n",
    "\n",
    "        self._evaluate_oob_savings(X, y, cost_mat)\n",
    "\n",
    "        if self.combination in ['stacking', 'stacking_proba', 'stacking_bmr', 'stacking_proba_bmr']:\n",
    "            self._fit_stacking_model(X, y, cost_mat)\n",
    "\n",
    "        if self.combination in ['majority_bmr', 'weighted_bmr', 'stacking_bmr', 'stacking_proba_bmr']:\n",
    "            self._fit_bmr_model(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit_bmr_model(self, X, y):\n",
    "        \"\"\"Private function used to fit the BayesMinimumRisk model.\"\"\"\n",
    "        self.f_bmr = BayesMinimumRiskClassifier()\n",
    "        X_bmr = self.predict_proba(X)\n",
    "        self.f_bmr.fit(y, X_bmr)\n",
    "        return self\n",
    "\n",
    "    def _fit_stacking_model(self, X, y, cost_mat, max_iter=100):\n",
    "        \"\"\"Private function used to fit the stacking model.\"\"\"\n",
    "        self.f_staking = CostSensitiveLogisticRegression(\n",
    "            verbose=self.verbose, max_iter=max_iter)\n",
    "        X_stacking = _create_stacking_set(self.estimators_, self.estimators_features_,\n",
    "                                          self.estimators_weight_, X, self.combination)\n",
    "        self.f_staking.fit(X_stacking, y, cost_mat)\n",
    "        return self\n",
    "\n",
    "    #TODO: _evaluate_oob_savings in parallel\n",
    "    def _evaluate_oob_savings(self, X, y, cost_mat):\n",
    "        \"\"\"Private function used to calculate the OOB Savings of each estimator.\"\"\"\n",
    "        estimators_weight = []\n",
    "        for estimator, samples, features in zip(self.estimators_, self.estimators_samples_,\n",
    "                                                self.estimators_features_):\n",
    "            # Test if all examples where used for training\n",
    "            if not np.any(~samples):\n",
    "                # Then use training\n",
    "                oob_pred = estimator.predict(X[:, features])\n",
    "                oob_savings = max(0, savings_score(y, oob_pred, cost_mat))\n",
    "            else:\n",
    "                # Then use OOB\n",
    "                oob_pred = estimator.predict((X[~samples])[:, features])\n",
    "                oob_savings = max(0, savings_score(\n",
    "                    y[~samples], oob_pred, cost_mat[~samples]))\n",
    "\n",
    "            estimators_weight.append(oob_savings)\n",
    "\n",
    "        # Control in case were all weights are 0\n",
    "        if sum(estimators_weight) == 0:\n",
    "            self.estimators_weight_ = np.ones(\n",
    "                len(estimators_weight)) / len(estimators_weight)\n",
    "        else:\n",
    "            self.estimators_weight_ = (\n",
    "                np.array(estimators_weight) / sum(estimators_weight)).tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _validate_y(self, y):\n",
    "        # Default implementation\n",
    "        return column_or_1d(y, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d97c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _partition_estimators(n_estimators, n_jobs):\n",
    "    \"\"\"Private function used to partition estimators between jobs.\"\"\"\n",
    "    # Compute the number of jobs\n",
    "    if n_jobs == -1:\n",
    "        n_jobs = min(cpu_count(), n_estimators)\n",
    "\n",
    "    else:\n",
    "        n_jobs = min(n_jobs, n_estimators)\n",
    "\n",
    "    # Partition estimators between jobs\n",
    "    n_estimators_per_job = (n_estimators // n_jobs) * np.ones(n_jobs,\n",
    "                                                              dtype=np.int64)\n",
    "    n_estimators_per_job[:n_estimators % n_jobs] += 1\n",
    "    starts = np.cumsum(n_estimators_per_job)\n",
    "\n",
    "    return n_jobs, n_estimators_per_job.tolist(), [0] + starts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c31dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_build_estimators(n_estimators, ensemble, X, y, cost_mat,\n",
    "                               seeds, verbose,min_samples_leaf, max_depth):#Chen Added min_samples_leaf and max_depth\n",
    "    \"\"\"Private function used to build a batch of estimators within a job.\"\"\"\n",
    "    # Retrieve settings\n",
    "    n_samples, n_features = X.shape\n",
    "    max_samples = ensemble.max_samples\n",
    "    max_features = ensemble.max_features\n",
    "\n",
    "    if (not isinstance(max_samples, (numbers.Integral, np.integer)) and\n",
    "            (0.0 < max_samples <= 1.0)):\n",
    "        max_samples = int(max_samples * n_samples)\n",
    "\n",
    "    if (not isinstance(max_features, (numbers.Integral, np.integer)) and\n",
    "            (0.0 < max_features <= 1.0)):\n",
    "        max_features = int(max_features * n_features)\n",
    "\n",
    "    bootstrap = ensemble.bootstrap\n",
    "    bootstrap_features = ensemble.bootstrap_features\n",
    "\n",
    "    # Build estimators\n",
    "    estimators = []\n",
    "    estimators_samples = []\n",
    "    estimators_features = []\n",
    "\n",
    "    for i in range(n_estimators):\n",
    "        if verbose > 1:\n",
    "            print((\"building estimator %d of %d\" % (i + 1, n_estimators)))\n",
    "\n",
    "        random_state = check_random_state(seeds[i])\n",
    "        seed = check_random_state(random_state.randint(MAX_INT))\n",
    "        estimator = ensemble._make_estimator(append=False)\n",
    "\n",
    "        try:  # Not all estimator accept a random_state\n",
    "            estimator.set_params(min_samples_leaf = min_samples_leaf, max_depth = max_depth, random_state=seed)#Chen Added min_samples_leaf and max_depth\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Draw features\n",
    "        if bootstrap_features:\n",
    "            features = random_state.randint(0, n_features, max_features)\n",
    "        else:\n",
    "            features = sample_without_replacement(n_features,\n",
    "                                                  max_features,\n",
    "                                                  random_state=random_state)\n",
    "\n",
    "        # Draw samples, using a mask, and then fit\n",
    "        if bootstrap:\n",
    "            indices = random_state.randint(0, n_samples, max_samples)\n",
    "        else:\n",
    "            indices = sample_without_replacement(n_samples,\n",
    "                                                 max_samples,\n",
    "                                                 random_state=random_state)\n",
    "\n",
    "        sample_counts = np.bincount(indices, minlength=n_samples)\n",
    "\n",
    "        estimator.fit((X[indices])[:, features],\n",
    "                      y[indices], cost_mat[indices, :])\n",
    "        samples = sample_counts > 0.\n",
    "\n",
    "        estimators.append(estimator)\n",
    "        estimators_samples.append(samples)\n",
    "        estimators_features.append(features)\n",
    "\n",
    "    return estimators, estimators_samples, estimators_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cc249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_predict_proba(estimators, estimators_features, X, n_classes, combination, estimators_weight):\n",
    "    \"\"\"Private function used to compute (proba-)predictions within a job.\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    proba = np.zeros((n_samples, n_classes))\n",
    "\n",
    "    for estimator, features, weight in zip(estimators, estimators_features, estimators_weight):\n",
    "        proba_estimator = estimator.predict_proba(X[:, features])\n",
    "        if combination in ['weighted_voting', 'weighted_bmr']:\n",
    "            proba += proba_estimator * weight\n",
    "        else:\n",
    "            proba += proba_estimator\n",
    "\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dad7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_predict(estimators, estimators_features, X, n_classes, combination, estimators_weight):\n",
    "    \"\"\"Private function used to compute predictions within a job.\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    pred = np.zeros((n_samples, n_classes))\n",
    "    n_estimators = len(estimators)\n",
    "\n",
    "    for estimator, features, weight in zip(estimators, estimators_features, estimators_weight):\n",
    "        # Resort to voting\n",
    "        predictions = estimator.predict(X[:, features])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if combination == 'weighted_voting':\n",
    "                pred[i, int(predictions[i])] += 1 * weight\n",
    "            else:\n",
    "                pred[i, int(predictions[i])] += 1\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a27996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaggingClassifier(BaseBagging, ClassifierMixin):\n",
    "    \"\"\"A Bagging classifier.\n",
    "\n",
    "    A Bagging classifier is an ensemble meta-estimator that fits base\n",
    "    classifiers each on random subsets of the original dataset and then\n",
    "    aggregate their individual predictions (either by voting or by averaging)\n",
    "    to form a final prediction. Such a meta-estimator can typically be used as\n",
    "    a way to reduce the variance of a black-box estimator (e.g., a decision\n",
    "    tree), by introducing randomization into its construction procedure and\n",
    "    then making an ensemble out of it.\n",
    "\n",
    "    This algorithm encompasses several works from the literature. When random\n",
    "    subsets of the dataset are drawn as random subsets of the samples, then\n",
    "    this algorithm is known as Pasting [1]_. If samples are drawn with\n",
    "    replacement, then the method is known as Bagging [2]_. When random subsets\n",
    "    of the dataset are drawn as random subsets of the features, then the method\n",
    "    is known as Random Subspaces [3]_. Finally, when base estimators are built\n",
    "    on subsets of both samples and features, then the method is known as\n",
    "    Random Patches [4]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator : object or None, optional (default=None)\n",
    "        The base estimator to fit on random subsets of the dataset.\n",
    "        If None, then the base estimator is a decision tree.\n",
    "\n",
    "    n_estimators : int, optional (default=10)\n",
    "        The number of base estimators in the ensemble.\n",
    "\n",
    "    max_samples : int or float, optional (default=1.0)\n",
    "        The number of samples to draw from X to train each base estimator.\n",
    "            - If int, then draw `max_samples` samples.\n",
    "            - If float, then draw `max_samples * X.shape[0]` samples.\n",
    "\n",
    "    max_features : int or float, optional (default=1.0)\n",
    "        The number of features to draw from X to train each base estimator.\n",
    "            - If int, then draw `max_features` features.\n",
    "            - If float, then draw `max_features * X.shape[1]` features.\n",
    "\n",
    "    bootstrap : boolean, optional (default=True)\n",
    "        Whether samples are drawn with replacement.\n",
    "\n",
    "    bootstrap_features : boolean, optional (default=False)\n",
    "        Whether features are drawn with replacement.\n",
    "\n",
    "    combination : string, optional (default=\"majority_voting\")\n",
    "        Which combination method to use:\n",
    "          - If \"majority_voting\" then combine by majority voting\n",
    "          - If \"weighted_voting\" then combine by weighted voting using the\n",
    "            out of bag savings as the weight for each estimator.\n",
    "          - If \"stacking\" then a Cost Sensitive Logistic Regression is used\n",
    "            to learn the combination.\n",
    "          - If \"stacking_proba\" then a Cost Sensitive Logistic Regression trained\n",
    "            with the estimated probabilities is used to learn the combination,.\n",
    "          - If \"stacking_bmr\" then a Cost Sensitive Logistic Regression is used\n",
    "            to learn the probabilities and a BayesMinimumRisk for the prediction.\n",
    "          - If \"stacking_proba_bmr\" then a Cost Sensitive Logistic Regression trained\n",
    "            with the estimated probabilities is used to learn the probabilities,\n",
    "            and a BayesMinimumRisk for the prediction.\n",
    "          - If \"majority_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
    "            prediction using the predicted probabilities of majority_voting\n",
    "          - If \"weighted_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
    "            prediction using the predicted probabilities of weighted_voting\n",
    "\n",
    "    n_jobs : int, optional (default=1)\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        If -1, then the number of jobs is set to the number of cores.\n",
    "\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    verbose : int, optional (default=0)\n",
    "        Controls the verbosity of the building process.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `base_estimator_`: list of estimators\n",
    "        The base estimator from which the ensemble is grown.\n",
    "\n",
    "    `estimators_`: list of estimators\n",
    "        The collection of fitted base estimators.\n",
    "\n",
    "    `estimators_samples_`: list of arrays\n",
    "        The subset of drawn samples (i.e., the in-bag samples) for each base\n",
    "        estimator.\n",
    "\n",
    "    `estimators_features_`: list of arrays\n",
    "        The subset of drawn features for each base estimator.\n",
    "\n",
    "    `classes_`: array of shape = [n_classes]\n",
    "        The classes labels.\n",
    "\n",
    "    `n_classes_`: int or list\n",
    "        The number of classes.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    .. [1] L. Breiman, \"Pasting small votes for classification in large\n",
    "           databases and on-line\", Machine Learning, 36(1), 85-103, 1999.\n",
    "\n",
    "    .. [2] L. Breiman, \"Bagging predictors\", Machine Learning, 24(2), 123-140,\n",
    "           1996.\n",
    "\n",
    "    .. [3] T. Ho, \"The random subspace method for constructing decision\n",
    "           forests\", Pattern Analysis and Machine Intelligence, 20(8), 832-844,\n",
    "           1998.\n",
    "\n",
    "    .. [4] G. Louppe and P. Geurts, \"Ensembles on Random Patches\", Machine\n",
    "           Learning and Knowledge Discovery in Databases, 346-361, 2012.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 base_estimator=None,\n",
    "                 n_estimators=10,\n",
    "                 max_samples=1.0,\n",
    "                 max_features=1.0,\n",
    "                 bootstrap=True,\n",
    "                 bootstrap_features=False,\n",
    "                 combination='voting',\n",
    "                 n_jobs=1,\n",
    "                 random_state=None,\n",
    "                 verbose=0):\n",
    "\n",
    "        super(BaggingClassifier, self).__init__(\n",
    "            base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            max_samples=max_samples,\n",
    "            max_features=max_features,\n",
    "            bootstrap=bootstrap,\n",
    "            bootstrap_features=bootstrap_features,\n",
    "            combination=combination,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "            verbose=verbose)\n",
    "\n",
    "    def _validate_estimator(self):\n",
    "        \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n",
    "        super(BaggingClassifier, self)._validate_estimator(\n",
    "            default=DecisionTreeClassifier())\n",
    "\n",
    "    def _validate_y(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def predict(self, X, cost_mat=None):\n",
    "        \"\"\"Predict class for X.\n",
    "\n",
    "        The predicted class of an input sample is computed as the class with\n",
    "        the highest mean predicted probability. If base estimators do not\n",
    "        implement a ``predict_proba`` method, then it resorts to voting.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrices are accepted only if\n",
    "            they are supported by the base estimator.\n",
    "\n",
    "        cost_mat : optional array-like of shape = [n_samples, 4], (default=None)\n",
    "            Cost matrix of the classification problem\n",
    "            Where the columns represents the costs of: false positives, false negatives,\n",
    "            true positives and true negatives, for each example.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred : array of shape = [n_samples]\n",
    "            The predicted classes.\n",
    "        \"\"\"\n",
    "        # Check data\n",
    "        # X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])  # Dont in version 0.15\n",
    "\n",
    "        if self.n_features_ != X.shape[1]:\n",
    "            raise ValueError(\"Number of features of the model must \"\n",
    "                             \"match the input. Model n_features is {0} and \"\n",
    "                             \"input n_features is {1}.\"\n",
    "                             \"\".format(self.n_features_, X.shape[1]))\n",
    "\n",
    "        # TODO: check if combination in possible combinations\n",
    "\n",
    "        if self.combination in ['stacking', 'stacking_proba']:\n",
    "\n",
    "            X_stacking = _create_stacking_set(self.estimators_, self.estimators_features_,\n",
    "                                              self.estimators_weight_, X, self.combination)\n",
    "            return self.f_staking.predict(X_stacking)\n",
    "\n",
    "        elif self.combination in ['majority_voting', 'weighted_voting']:\n",
    "            # Parallel loop\n",
    "            n_jobs, n_estimators, starts = _partition_estimators(self.n_estimators,\n",
    "                                                                 self.n_jobs)\n",
    "\n",
    "            all_pred = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
    "                delayed(_parallel_predict)(\n",
    "                    self.estimators_[starts[i]:starts[i + 1]],\n",
    "                    self.estimators_features_[starts[i]:starts[i + 1]],\n",
    "                    X,\n",
    "                    self.n_classes_,\n",
    "                    self.combination,\n",
    "                    self.estimators_weight_[starts[i]:starts[i + 1]])\n",
    "                for i in range(n_jobs))\n",
    "\n",
    "            # Reduce\n",
    "            pred = sum(all_pred) / self.n_estimators\n",
    "\n",
    "            return self.classes_.take(np.argmax(pred, axis=1), axis=0)\n",
    "\n",
    "        elif self.combination in ['majority_bmr', 'weighted_bmr', 'stacking_bmr', 'stacking_proba_bmr']:\n",
    "            # TODO: Add check if cost_mat == None\n",
    "            X_bmr = self.predict_proba(X)\n",
    "            return self.f_bmr.predict(X_bmr, cost_mat)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X.\n",
    "\n",
    "        The predicted class probabilities of an input sample is computed as\n",
    "        the mean predicted class probabilities of the base estimators in the\n",
    "        ensemble. If base estimators do not implement a ``predict_proba``\n",
    "        method, then it resorts to voting and the predicted class probabilities\n",
    "        of a an input sample represents the proportion of estimators predicting\n",
    "        each class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrices are accepted only if\n",
    "            they are supported by the base estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_classes]\n",
    "            The class probabilities of the input samples. The order of the\n",
    "            classes corresponds to that in the attribute `classes_`.\n",
    "        \"\"\"\n",
    "        # Check data\n",
    "        # X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])  # Dont in version 0.15\n",
    "\n",
    "        if self.n_features_ != X.shape[1]:\n",
    "            raise ValueError(\"Number of features of the model must \"\n",
    "                             \"match the input. Model n_features is {0} and \"\n",
    "                             \"input n_features is {1}.\"\n",
    "                             \"\".format(self.n_features_, X.shape[1]))\n",
    "\n",
    "        # Parallel loop\n",
    "        n_jobs, n_estimators, starts = _partition_estimators(\n",
    "            self.n_estimators, self.n_jobs)\n",
    "\n",
    "        all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
    "            delayed(_parallel_predict_proba)(\n",
    "                self.estimators_[starts[i]:starts[i + 1]],\n",
    "                self.estimators_features_[starts[i]:starts[i + 1]],\n",
    "                X,\n",
    "                self.n_classes_,\n",
    "                self.combination,\n",
    "                self.estimators_weight_[starts[i]:starts[i + 1]])\n",
    "            for i in range(n_jobs))\n",
    "\n",
    "        # Reduce\n",
    "        if self.combination in ['majority_voting', 'majority_bmr']:\n",
    "            proba = sum(all_proba) / self.n_estimators\n",
    "        elif self.combination in ['weighted_voting', 'weighted_bmr']:\n",
    "            proba = sum(all_proba)\n",
    "        elif self.combination in ['stacking', 'stacking_proba', 'stacking_bmr', 'stacking_proba_bmr']:\n",
    "            X_stacking = _create_stacking_set(self.estimators_, self.estimators_features_,\n",
    "                                              self.estimators_weight_, X, self.combination)\n",
    "            proba = self.f_staking.predict_proba(X_stacking)\n",
    "\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b4a0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostSensitiveRandomForestClassifier(BaggingClassifier):\n",
    "    \"\"\"A example-dependent cost-sensitive random forest  classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    n_estimators : int, optional (default=10)\n",
    "        The number of base estimators in the ensemble.\n",
    "\n",
    "    combination : string, optional (default=\"majority_voting\")\n",
    "        Which combination method to use:\n",
    "          - If \"majority_voting\" then combine by majority voting\n",
    "          - If \"weighted_voting\" then combine by weighted voting using the\n",
    "            out of bag savings as the weight for each estimator.\n",
    "          - If \"stacking\" then a Cost Sensitive Logistic Regression is used\n",
    "            to learn the combination.\n",
    "          - If \"stacking_proba\" then a Cost Sensitive Logistic Regression trained\n",
    "            with the estimated probabilities is used to learn the combination,.\n",
    "          - If \"stacking_bmr\" then a Cost Sensitive Logistic Regression is used\n",
    "            to learn the probabilities and a BayesMinimumRisk for the prediction.\n",
    "          - If \"stacking_proba_bmr\" then a Cost Sensitive Logistic Regression trained\n",
    "            with the estimated probabilities is used to learn the probabilities,\n",
    "            and a BayesMinimumRisk for the prediction.\n",
    "          - If \"majority_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
    "            prediction using the predicted probabilities of majority_voting\n",
    "          - If \"weighted_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
    "            prediction using the predicted probabilities of weighted_voting\n",
    "\n",
    "    max_features : int, float, string or None, optional (default=None)\n",
    "        The number of features to consider when looking for the best split in each tree:\n",
    "          - If int, then consider `max_features` features at each split.\n",
    "          - If float, then `max_features` is a percentage and\n",
    "            `int(max_features * n_features)` features are considered at each\n",
    "            split.\n",
    "          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
    "          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
    "          - If \"log2\", then `max_features=log2(n_features)`.\n",
    "          - If None, then `max_features=n_features`.\n",
    "\n",
    "        Note: the search for a split does not stop until at least one\n",
    "        valid partition of the node samples is found, even if it requires to\n",
    "        effectively inspect more than ``max_features`` features.\n",
    "\n",
    "    pruned : bool, optional (default=True)\n",
    "        Whenever or not to prune the decision tree using cost-based pruning\n",
    "\n",
    "    n_jobs : int, optional (default=1)\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        If -1, then the number of jobs is set to the number of cores.\n",
    "\n",
    "    verbose : int, optional (default=0)\n",
    "        Controls the verbosity of the building process.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `base_estimator_`: list of estimators\n",
    "        The base estimator from which the ensemble is grown.\n",
    "\n",
    "    `estimators_`: list of estimators\n",
    "        The collection of fitted base estimators.\n",
    "\n",
    "    `estimators_samples_`: list of arrays\n",
    "        The subset of drawn samples (i.e., the in-bag samples) for each base\n",
    "        estimator.\n",
    "\n",
    "    `estimators_features_`: list of arrays\n",
    "        The subset of drawn features for each base estimator.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    costcla.models.CostSensitiveDecisionTreeClassifier\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    .. [1] Correa Bahnsen, A., Aouada, D., & Ottersten, B.\n",
    "           `\"Ensemble of Example-Dependent Cost-Sensitive Decision Trees\" <http://arxiv.org/abs/1505.04637>`__,\n",
    "           2015, http://arxiv.org/abs/1505.04637.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.ensemble import RandomForestClassifier\n",
    "    >>> from sklearn.cross_validation import train_test_split\n",
    "    >>> from costcla.datasets import load_creditscoring1\n",
    "    >>> from costcla.models import CostSensitiveRandomForestClassifier\n",
    "    >>> from costcla.metrics import savings_score\n",
    "    >>> data = load_creditscoring1()\n",
    "    >>> sets = train_test_split(data.data, data.target, data.cost_mat, test_size=0.33, random_state=0)\n",
    "    >>> X_train, X_test, y_train, y_test, cost_mat_train, cost_mat_test = sets\n",
    "    >>> y_pred_test_rf = RandomForestClassifier(random_state=0).fit(X_train, y_train).predict(X_test)\n",
    "    >>> f = CostSensitiveRandomForestClassifier()\n",
    "    >>> y_pred_test_csdt = f.fit(X_train, y_train, cost_mat_train).predict(X_test)\n",
    "    >>> # Savings using only RandomForest\n",
    "    >>> print(savings_score(y_test, y_pred_test_rf, cost_mat_test))\n",
    "    0.12454256594\n",
    "    >>> # Savings using CostSensitiveRandomForestClassifier\n",
    "    >>> print(savings_score(y_test, y_pred_test_csdt, cost_mat_test))\n",
    "    0.499390945808\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_estimators=10,\n",
    "                 combination='majority_voting',\n",
    "                 max_features='auto',\n",
    "                 n_jobs=1,\n",
    "                 verbose=False,\n",
    "                 pruned=False,\n",
    "                 min_samples_leaf = 5, \n",
    "                 max_depth = 10\n",
    "\n",
    "                ):\n",
    "        super(BaggingClassifier, self).__init__(\n",
    "            base_estimator=CostSensitiveDecisionTreeClassifier(max_features=max_features, pruned=pruned, min_samples_leaf = min_samples_leaf, max_depth = max_depth ),\n",
    "            n_estimators=n_estimators,\n",
    "            max_samples=1.0,\n",
    "            max_features=1.0,\n",
    "            bootstrap=True,\n",
    "            bootstrap_features=False,\n",
    "            combination=combination,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=None,\n",
    "            verbose=verbose)\n",
    "        self.pruned = pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d1c6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CostSensitiveRandomForestClassifier in module __main__ object:\n",
      "\n",
      "class CostSensitiveRandomForestClassifier(BaggingClassifier)\n",
      " |  CostSensitiveRandomForestClassifier(n_estimators=10, combination='majority_voting', max_features='auto', n_jobs=1, verbose=False, pruned=False, min_samples_leaf=5, max_depth=10)\n",
      " |  \n",
      " |  A example-dependent cost-sensitive random forest  classifier.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  n_estimators : int, optional (default=10)\n",
      " |      The number of base estimators in the ensemble.\n",
      " |  \n",
      " |  combination : string, optional (default=\"majority_voting\")\n",
      " |      Which combination method to use:\n",
      " |        - If \"majority_voting\" then combine by majority voting\n",
      " |        - If \"weighted_voting\" then combine by weighted voting using the\n",
      " |          out of bag savings as the weight for each estimator.\n",
      " |        - If \"stacking\" then a Cost Sensitive Logistic Regression is used\n",
      " |          to learn the combination.\n",
      " |        - If \"stacking_proba\" then a Cost Sensitive Logistic Regression trained\n",
      " |          with the estimated probabilities is used to learn the combination,.\n",
      " |        - If \"stacking_bmr\" then a Cost Sensitive Logistic Regression is used\n",
      " |          to learn the probabilities and a BayesMinimumRisk for the prediction.\n",
      " |        - If \"stacking_proba_bmr\" then a Cost Sensitive Logistic Regression trained\n",
      " |          with the estimated probabilities is used to learn the probabilities,\n",
      " |          and a BayesMinimumRisk for the prediction.\n",
      " |        - If \"majority_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
      " |          prediction using the predicted probabilities of majority_voting\n",
      " |        - If \"weighted_bmr\" then the BayesMinimumRisk algorithm is used to make the\n",
      " |          prediction using the predicted probabilities of weighted_voting\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split in each tree:\n",
      " |        - If int, then consider `max_features` features at each split.\n",
      " |        - If float, then `max_features` is a percentage and\n",
      " |          `int(max_features * n_features)` features are considered at each\n",
      " |          split.\n",
      " |        - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |        - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |        - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  pruned : bool, optional (default=True)\n",
      " |      Whenever or not to prune the decision tree using cost-based pruning\n",
      " |  \n",
      " |  n_jobs : int, optional (default=1)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      If -1, then the number of jobs is set to the number of cores.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity of the building process.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  `base_estimator_`: list of estimators\n",
      " |      The base estimator from which the ensemble is grown.\n",
      " |  \n",
      " |  `estimators_`: list of estimators\n",
      " |      The collection of fitted base estimators.\n",
      " |  \n",
      " |  `estimators_samples_`: list of arrays\n",
      " |      The subset of drawn samples (i.e., the in-bag samples) for each base\n",
      " |      estimator.\n",
      " |  \n",
      " |  `estimators_features_`: list of arrays\n",
      " |      The subset of drawn features for each base estimator.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  costcla.models.CostSensitiveDecisionTreeClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] Correa Bahnsen, A., Aouada, D., & Ottersten, B.\n",
      " |         `\"Ensemble of Example-Dependent Cost-Sensitive Decision Trees\" <http://arxiv.org/abs/1505.04637>`__,\n",
      " |         2015, http://arxiv.org/abs/1505.04637.\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.cross_validation import train_test_split\n",
      " |  >>> from costcla.datasets import load_creditscoring1\n",
      " |  >>> from costcla.models import CostSensitiveRandomForestClassifier\n",
      " |  >>> from costcla.metrics import savings_score\n",
      " |  >>> data = load_creditscoring1()\n",
      " |  >>> sets = train_test_split(data.data, data.target, data.cost_mat, test_size=0.33, random_state=0)\n",
      " |  >>> X_train, X_test, y_train, y_test, cost_mat_train, cost_mat_test = sets\n",
      " |  >>> y_pred_test_rf = RandomForestClassifier(random_state=0).fit(X_train, y_train).predict(X_test)\n",
      " |  >>> f = CostSensitiveRandomForestClassifier()\n",
      " |  >>> y_pred_test_csdt = f.fit(X_train, y_train, cost_mat_train).predict(X_test)\n",
      " |  >>> # Savings using only RandomForest\n",
      " |  >>> print(savings_score(y_test, y_pred_test_rf, cost_mat_test))\n",
      " |  0.12454256594\n",
      " |  >>> # Savings using CostSensitiveRandomForestClassifier\n",
      " |  >>> print(savings_score(y_test, y_pred_test_csdt, cost_mat_test))\n",
      " |  0.499390945808\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CostSensitiveRandomForestClassifier\n",
      " |      BaggingClassifier\n",
      " |      BaseBagging\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=10, combination='majority_voting', max_features='auto', n_jobs=1, verbose=False, pruned=False, min_samples_leaf=5, max_depth=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: __main__.CostSensitiveRandomForestClassifier, *, cost_mat: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> __main__.CostSensitiveRandomForestClassifier\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cost_mat : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``cost_mat`` parameter in ``fit``.\n",
      " |      \n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_predict_request(self: __main__.CostSensitiveRandomForestClassifier, *, cost_mat: Union[bool, NoneType, str] = '$UNCHANGED$') -> __main__.CostSensitiveRandomForestClassifier\n",
      " |      Request metadata passed to the ``predict`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cost_mat : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``cost_mat`` parameter in ``predict``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: __main__.CostSensitiveRandomForestClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> __main__.CostSensitiveRandomForestClassifier\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaggingClassifier:\n",
      " |  \n",
      " |  predict(self, X, cost_mat=None)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the class with\n",
      " |      the highest mean predicted probability. If base estimators do not\n",
      " |      implement a ``predict_proba`` method, then it resorts to voting.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      cost_mat : optional array-like of shape = [n_samples, 4], (default=None)\n",
      " |          Cost matrix of the classification problem\n",
      " |          Where the columns represents the costs of: false positives, false negatives,\n",
      " |          true positives and true negatives, for each example.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pred : array of shape = [n_samples]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the mean predicted class probabilities of the base estimators in the\n",
      " |      ensemble. If base estimators do not implement a ``predict_proba``\n",
      " |      method, then it resorts to voting and the predicted class probabilities\n",
      " |      of a an input sample represents the proportion of estimators predicting\n",
      " |      each class.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes]\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseBagging:\n",
      " |  \n",
      " |  fit(self, X, y, cost_mat, sample_weight=None)\n",
      " |      Build a Bagging ensemble of estimators from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      cost_mat : array-like of shape = [n_samples, 4]\n",
      " |          Cost matrix of the classification problem\n",
      " |          Where the columns represents the costs of: false positives, false negatives,\n",
      " |          true positives and true negatives, for each example.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted.\n",
      " |          Note that this is supported only if the base estimator supports\n",
      " |          sample weighting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CostSensitiveRandomForestClassifier()\n",
    "help(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91b55f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17ec08",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(X_train, y_train, depth, samples):\n",
    "    model = DecisionTreeClassifier(min_samples_leaf = samples, max_depth = depth)\n",
    "    model.fit(X_train, y_train) \n",
    "    loops = 0\n",
    "    return model, loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668aca48",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d34269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train, y_train, depth, samples):\n",
    "    model = RandomForestClassifier(min_samples_leaf = samples, max_depth = depth, n_jobs = 1)\n",
    "    model.fit(X_train, y_train)\n",
    "    loops = 0\n",
    "    return model, loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1dfc5",
   "metadata": {},
   "source": [
    "## Cost Sensitive Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54113ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(X_train, y_train, depth, samples, cost_matrix):\n",
    "    model = CostSensitiveDecisionTreeClassifier() #The base object, we will train it.\n",
    "    model.set_params(min_samples_leaf= samples, max_depth= depth, pruned = True, min_gain = 0.01)\n",
    "    model.fit(X_train.to_numpy(), y_train.to_numpy(), prepare_for_cost_cle(len(X_train), cost_matrix))     \n",
    "    loops = 0\n",
    "    return model, loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac1d2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaCSL_WRC(X_train, y_train, X_test, constraint, depth, samples ,if_cfp_equal_cfn):\n",
    "    effective_threshold = 1.0 \n",
    "    \n",
    "    if if_cfp_equal_cfn:\n",
    "        cfp = cfn = 1\n",
    "    else:\n",
    "        cfp = 0\n",
    "        cfn = 10\n",
    "    \n",
    "    loops = 0\n",
    "    \n",
    "    for i in range(50):\n",
    "        loops += 1\n",
    "        cfp += 1 \n",
    "        threshold = cfp/(cfp+cfn)\n",
    "        print(\n",
    "            f\"Threshold: {threshold:.2f}\", \n",
    "            f\"Effective Threshold: {effective_threshold:.2f}\", \n",
    "            f\"Cost False Positive: {cfp:.2f}\", \n",
    "            sep = \" \", end=\"\\r\", flush=True)\n",
    "        \n",
    "        cost_matrix = np.array([[0, cfp], \n",
    "                                [cfn, 0]])\n",
    "        \n",
    "        model_i,_ = cs(X_train, y_train, depth, samples, cost_matrix) #create a cs model \n",
    "        \n",
    "        #set the effective threshold according to the X_test \n",
    "        y_pred_proba = model_i.predict_proba(X_test.to_numpy())[:, 1]\n",
    "        effective_threshold = find_effective_threshold(y_pred_proba, constraint, threshold) \n",
    "      \n",
    "        #The binary search, if we overshot, we need to decrease cfp\n",
    "        if effective_threshold <= threshold: \n",
    "            break\n",
    "\n",
    "        \n",
    "    best_model_ = deepcopy(model_i) #This one is already trained.\n",
    "    cfp_ = cfp\n",
    "    threshold_ = threshold\n",
    "    \n",
    "    print(\"\\nDONE\")\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Effective threshold: {effective_threshold:.2f}\")\n",
    "    print(\"Current cfp: \", cfp)\n",
    "    return best_model_ , loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3b323",
   "metadata": {},
   "source": [
    "## Cost Sensitive Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "435868cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cs(X_train, y_train, depth, samples, cost_matrix):\n",
    "    model = CostSensitiveRandomForestClassifier() #The base object, we will train it.\n",
    "    model.set_params(min_samples_leaf= samples, max_depth= depth, n_estimators = 100, n_jobs = -1)\n",
    "    model.fit(X_train, y_train, cost_mat = prepare_for_cost_cle(len(X_train), cost_matrix))     \n",
    "    loops = 0\n",
    "    return model, loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b961367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_rf_cs(X_train, y_train, constraint, depth, samples ,if_cfp_equal_cfn):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    loops = 0\n",
    "    return model, loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911fe75",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cd43098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_acc(n_pos, const, n_cred):\n",
    "    if n_pos > const:\n",
    "        return (const + n_cred - n_pos)/n_cred\n",
    "    else: \n",
    "        return (n_pos + n_cred - const)/n_cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29e5303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groupby_df(mask_dates, mask_test_provider, min_const=0.9, max_const=0.7):\n",
    "    groupby_df = pd.DataFrame(df[mask_dates & mask_test_provider].groupby('prediction_date')['target'].sum())\n",
    "    n_cred = ((df[mask_dates & mask_test_provider].shape[0]/10))\n",
    "    groupby_df = groupby_df.rename(columns={'target': 'n_positive'})\n",
    "    groupby_df['%positive'] = groupby_df['n_positive']/n_cred\n",
    "    constraints_list = []\n",
    "    constraints_list.append(np.round(groupby_df['n_positive'].min()*min_const)) # the constraint is about 90 percent from the minimum positives in the test dates - can be changed\n",
    "    constraints_list.append(np.round(groupby_df['n_positive'].max()*max_const))\n",
    "    for i, constraint in enumerate(constraints_list):\n",
    "        groupby_df[f'%constraint_{i}'] = constraint/groupby_df['n_positive']\n",
    "    return groupby_df, constraints_list, n_cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "165aeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(uuid ,provider, date, max_accuracy, model_name, constraint,best_params, loops_in_model, best_model_duration, all_duration, cost, accuracy, precision, recall, f1):\n",
    "    # General Results File\n",
    "    results_file = 'results/all_results.csv'\n",
    "    \n",
    "    output = f'{uuid},{provider},{date},{max_accuracy},{model_name},{constraint},{best_params},{loops_in_model},{best_model_duration},{all_duration},{cost},{accuracy},{precision},{recall},{f1}'\n",
    "    if not os.path.exists(results_file):\n",
    "        with open(results_file, 'a') as output_file:  # 'a' for append to end of file\n",
    "            headlines = 'uuid,provider,date,max_accuracy,model_name,constraint,best_params,loops_in_model,best_model_duration,all_duration,cost,accuracy,precision,recall,f1'\n",
    "            output_file.write(headlines + \"\\n\" + output + \"\\n\")\n",
    "    else:\n",
    "        with open(results_file, 'a') as output_file:  # 'a' for append to end of file\n",
    "            output_file.write(output + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ae715",
   "metadata": {},
   "source": [
    "## Train models\n",
    "A function that trains each model according to our template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "458a89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X_train, y_train, X_val, y_val, X_test, constraint, model_name, cost_matrix, depths, nums_samples_leaf):\n",
    "    assert model_name in ['dt', 'rf', 'cs', 'rf_cs', 'AdaCSL_WRC','constrain_rf_cs','cfn=cfp AdaCSL_WRC','cfn=cfp constrain_rf_cs']\n",
    "    \n",
    "    best_acc = [0,0,0] #best acc is first, second the depth and third the min sample on leaf in the model of the best acc \n",
    "    all_duration = 0\n",
    "    for depth in depths:\n",
    "        for samples in nums_samples_leaf:\n",
    "            start = default_timer() #set start time of training\n",
    "            #fit the model \n",
    "            model ,loops_in_model = {\n",
    "                    'dt': lambda: dt(X_train, y_train, depth, samples),\n",
    "                    'rf': lambda: rf(X_train, y_train, depth, samples),\n",
    "                    'cs': lambda: cs(X_train, y_train, depth, samples, np.array([[0, 0],[10, 0]])),\n",
    "                    'rf_cs': lambda: rf_cs(X_train, y_train, depth, samples,np.array([[0,0],[10, 0]])),\n",
    "                    'AdaCSL_WRC': lambda: AdaCSL_WRC(X_train, y_train, X_test, constraint, depth, samples ,if_cfp_equal_cfn = False),\n",
    "                    'constrain_rf_cs': lambda: constrain_rf_cs(X_train, y_train, constraint, depth, samples ,if_cfp_equal_cfn = False),\n",
    "                    'cfn=cfp constrain_rf_cs': lambda: constrain_rf_cs(X_train, y_train, constraint, depth, samples ,if_cfp_equal_cfn = True),\n",
    "                    'cfn=cfp AdaCSL_WRC': lambda: AdaCSL_WRC(X_train, y_train, X_test, constraint, depth, samples ,if_cfp_equal_cfn = True)\n",
    "                    }[model_name]()\n",
    "            \n",
    "            duration = default_timer() - start #clac the duration\n",
    "            all_duration += duration\n",
    "            \n",
    "            #evaluate validation\n",
    "            y_val_pred = model.predict(X_val.to_numpy()) #val preds\n",
    "            vlues = evaluate(y_val, y_val_pred, cost_matrix)\n",
    "            \n",
    "            if best_acc[0] < vlues['accuracy']:#changing the values for the better model\n",
    "                best_acc[0] = vlues['accuracy']\n",
    "                best_acc[1] = depth\n",
    "                best_acc[2] = samples\n",
    "                best_model = model\n",
    "                best_model_duration = duration\n",
    "                \n",
    "    return best_model ,f'depth = {best_acc[1]} and min_smaple = {best_acc[2]}', loops_in_model ,best_model_duration , all_duration \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e26ba5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, X_test, y_test, constraint):\n",
    "    y_pred_proba = model.predict_proba(X_test.to_numpy())[:, 1] #get test prediction\n",
    "    y_pred_constrained = prediction_up_to_constraint(y_pred_proba, constraint) #only until the constraint\n",
    "    values = evaluate(y_test, y_pred_constrained, cost_matrix) #evluate values\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7496a",
   "metadata": {},
   "source": [
    "# Run Expriment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85139c",
   "metadata": {},
   "source": [
    "## Data-specific code\n",
    "\n",
    "This part includes some data-specific code. It is not included in the final model. <br>\n",
    "The X and the y are the dataframes that are used for training and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0834a9",
   "metadata": {},
   "source": [
    "###### Get credentialset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff266016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29804, 26)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/feature_dataset_500_no_missing.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b408b9",
   "metadata": {},
   "source": [
    "###### Get Providers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af3fe597",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_ids = pickle.load(open(\"data\\provider_ids.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21492052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_provider = df.join(provider_ids, on='credentialset_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "710620d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['856f211d-c66e-4db7-b910-7419900a70e1'], dtype='object', name='provider_id')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "providers_list = df_with_provider['provider_id'].value_counts()[3:4].index\n",
    "providers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7f36e",
   "metadata": {},
   "source": [
    "##### Set Cost Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a86506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COST_FALSE_NEGATIVE = 10\n",
    "COST_FALSE_POSITIVE = 1\n",
    "cost_matrix = np.array([[0, COST_FALSE_POSITIVE], [COST_FALSE_NEGATIVE, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59dba9",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "51b8105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = np.sort(df['prediction_date'].unique()[-7:])\n",
    "val_dates = np.sort(df['prediction_date'].unique()[-14:-7])\n",
    "mask_dates = df['prediction_date'].isin(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "11c81de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 24.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  24\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.76 Effective Threshold: 0.88 Cost False Positive: 31.00\n",
      "DONE\n",
      "Threshold: 0.76\n",
      "Effective threshold: 0.76\n",
      "Current cfp:  31\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.81 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.80 Effective Threshold: 0.88 Cost False Positive: 4.00\n",
      "DONE\n",
      "Threshold: 0.80\n",
      "Effective threshold: 0.80\n",
      "Current cfp:  4\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.66 Effective Threshold: 0.82 Cost False Positive: 19.00\n",
      "DONE\n",
      "Threshold: 0.66\n",
      "Effective threshold: 0.66\n",
      "Current cfp:  19\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.73 Effective Threshold: 0.86 Cost False Positive: 27.00\n",
      "DONE\n",
      "Threshold: 0.73\n",
      "Effective threshold: 0.73\n",
      "Current cfp:  27\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 0.83 Cost False Positive: 20.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  20\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.84 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.55 Effective Threshold: 0.72 Cost False Positive: 12.00\n",
      "DONE\n",
      "Threshold: 0.55\n",
      "Effective threshold: 0.55\n",
      "Current cfp:  12\n",
      "Threshold: 0.55 Effective Threshold: 0.72 Cost False Positive: 12.00\n",
      "DONE\n",
      "Threshold: 0.55\n",
      "Effective threshold: 0.55\n",
      "Current cfp:  12\n",
      "Threshold: 0.55 Effective Threshold: 0.72 Cost False Positive: 12.00\n",
      "DONE\n",
      "Threshold: 0.55\n",
      "Effective threshold: 0.55\n",
      "Current cfp:  12\n",
      "Threshold: 0.52 Effective Threshold: 0.73 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.52 Effective Threshold: 0.73 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.52 Effective Threshold: 0.71 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.52 Effective Threshold: 0.73 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.52 Effective Threshold: 0.73 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.52 Effective Threshold: 0.71 Cost False Positive: 11.00\n",
      "DONE\n",
      "Threshold: 0.52\n",
      "Effective threshold: 0.52\n",
      "Current cfp:  11\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.38 Effective Threshold: 0.59 Cost False Positive: 6.00\n",
      "DONE\n",
      "Threshold: 0.38\n",
      "Effective threshold: 0.38\n",
      "Current cfp:  6\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.71 Effective Threshold: 0.86 Cost False Positive: 25.00\n",
      "DONE\n",
      "Threshold: 0.71\n",
      "Effective threshold: 0.71\n",
      "Current cfp:  25\n",
      "Threshold: 0.09 Effective Threshold: 1.00 Cost False Positive: 1.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.64 Effective Threshold: 0.82 Cost False Positive: 18.00\n",
      "DONE\n",
      "Threshold: 0.64\n",
      "Effective threshold: 0.64\n",
      "Current cfp:  18\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.75 Effective Threshold: 0.83 Cost False Positive: 3.00\n",
      "DONE\n",
      "Threshold: 0.75\n",
      "Effective threshold: 0.75\n",
      "Current cfp:  3\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n",
      "Threshold: 0.67 Effective Threshold: 1.00 Cost False Positive: 2.00\n",
      "DONE\n",
      "Threshold: 0.67\n",
      "Effective threshold: 0.67\n",
      "Current cfp:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amith\\AppData\\Local\\Temp\\ipykernel_26276\\381021599.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n"
     ]
    }
   ],
   "source": [
    "import uuid #dont need to be here.. its in the import section i dont know why its not working \n",
    "\n",
    "models_name = ['dt','rf','cs','AdaCSL_WRC','cfn=cfp AdaCSL_WRC']#, 'cs', 'rf_cs', 'AdaCSL_WRC','constrain_rf_cs','cfn=cfp AdaCSL_WRC','cfn=cfp constrain_rf_cs']\n",
    "depths = [3,5,10]\n",
    "nums_samples_leaf = [5,15,50]\n",
    "\n",
    "for provider in providers_list:\n",
    "    uuid = str(uuid.uuid4())\n",
    "    mask_test_val_provider = df_with_provider['provider_id'] == provider\n",
    "    provider_groupby_df, constraints_list, n_cred = create_groupby_df(mask_dates, mask_test_val_provider)\n",
    "\n",
    "    for i, date in enumerate(test_dates):\n",
    "        #create mask dates \n",
    "        mask_train_dates = df['prediction_date'].isin(df['prediction_date'].unique()[i:-14+i])\n",
    "        mask_test_date = df['prediction_date'] == date\n",
    "        mask_val_date = df['prediction_date'] == val_dates[i]\n",
    "        \n",
    "        # creae test val and train \n",
    "        X_train = df[mask_train_dates].drop(labels=['credentialset_id', 'prediction_date', 'target'], axis=1)\n",
    "        X_test = df[mask_test_val_provider & mask_test_date].drop(labels=['credentialset_id', 'prediction_date', 'target'], axis=1)\n",
    "        X_val = df[mask_test_val_provider & mask_val_date].drop(labels=['credentialset_id', 'prediction_date', 'target'], axis=1)\n",
    "        y_train = df[mask_train_dates]['target']\n",
    "        y_test = df[mask_test_date & mask_test_val_provider]['target']\n",
    "        y_val = df[mask_val_date & mask_test_val_provider]['target']\n",
    "        \n",
    "        #loop model\n",
    "        for model_name in models_name:\n",
    "            #loop constraints\n",
    "            for num, constraint in enumerate(constraints_list):\n",
    "                const = constraint/len(y_test)\n",
    "                #create model\n",
    "                model ,best_params, loops_in_model ,best_model_duration ,all_duration  = model_train(X_train, y_train, X_val, y_val, X_test, const, model_name, cost_matrix, depths, nums_samples_leaf)\n",
    "                #test model\n",
    "                values = model_test(model,  X_test, y_test, const)\n",
    "                #best accuracy\n",
    "                max_accuracy = calc_max_acc(provider_groupby_df['n_positive'][i], constraint, len(y_test))\n",
    "                #store resualts\n",
    "                store_results(uuid, provider, date, max_accuracy, model_name, constraint ,best_params, loops_in_model, best_model_duration, all_duration, values['cost'], values['accuracy'], values['precision'], values['recall'], values['f1'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef588a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
